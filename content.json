{"pages":[],"posts":[{"title":"德国驾照备考：单词篇","text":"动词 | - ———| ————-vorbeifahren | 驶过，超车überfahren | 驶过，轧过abknicken | 急转弯，拐弯hochschalten | 换高速挡warmlaufen | (内燃机)预热运转,空转beladen | 装货，装载entladen | 卸货，卸载entbinden | 解除，免除beteiligen | 参加，加入vorweisen | 表现出，出示verrutschen | 打滑，滑落 形容词 | - ———| ————-zügig | 迅速的,流畅的mäßig | 适度的,适中的,适当的grobstollig | 高凸块花纹的niedertourig | 低转速的fachgerecht | 专业的bergab | 向下，下坡 advhektisch | 慌忙的，仓促的rasant | 迅速的，飞快的ausgeglich | 均衡的unverzüglich | 刻不容缓的，立即的，马上的entbehrlich | 可有可无的，非必要的vorausschauend | adv. 前瞻性的，有远见的，有先见之明的funktionstüchtig | 作用良好的,能运转的vorschriftsmäßig | 合乎规定的,按照规定的veischneit | 积雪的，白雪覆盖的 名词 | - ———| ————-das Schienenfahrzeug | 有轨机动车，铁道机车das Einsatzfahrzeug | 紧急任务车辆der Abschleppwagen | 拖吊车，救助牵引车der Streifenwagen | (警察)巡逻车die Fahne -n | 旗，旗帜der Tunnel - | 隧道der Zebrastreifen | 斑马线, 人行横道der Reißverschlussverfahren| 拉链式并道方法die Sackgasse -n | 死胡同die Unterführung | 地下通道，隧道die Umleitung | 交通改道，绕行das Standlicht | 停车灯，驻车灯das Abblendlicht | 近光灯die Panne | 故障，事故，损失，崩溃，漏洞die Zollstelle | 关卡，关税检查站das Gefahrgutfahrzeug | 危险货运汽车die Umweltschonung | 环保die Einspritzanlage | 喷射装置，喷射设备die unterschreitung | 低于额定，下降der Reifenabrieb | 轮胎磨损der Schalldämpfer | 消音装置der Schmierstoff | 润滑油die Entsorgung | 排除，清除die Bahnschranke | 铁路道口栅栏，拦道木der Bahnübergang | 铁路交叉道口der Lokführer | 火车司机der Leichtlauföl | 轻质汽油die Auspuffsanlage | 排气装置der Gang | 档位die Fahrweise | (汽车司机的)行车方式(尤指对待行人、骑车人或同行的态度)das Kondenswasser | 冷凝水der Verschleiß | 磨损，损耗der Qualm | 浓烟das Einsatzhorn | 警报声，汽笛声die Fliekraft | 离心力der Fahrtwind | 迎面风，气流die Geschädigte | 受害者der Transponder | 发射应答器，应答器die Autobahnraststätte | 高速公路休息处die Notrufsäule | (高速公路旁)紧急救援电话(柱)der Leitpfosten | 导向柱die Leitplanke | (公路两旁的)护栏,安全栏,护板das Rufzeichen | 呼叫信号，呼叫音die Bake | 浮标,航标,路标der Schachtdeckel | 窨井盖die Lackierung | 油漆，喷漆","link":"/2019/12/28/German%20Driver's%20_license_words/"},{"title":"德国交规：停车与泊车","text":"Parken基本规则 只能在有泊车标志的区域泊车 街道右侧泊车（单向车道和右侧有铁轨的街道例外，可以左侧停车） 机动车辆在没有拖车的情况下可以在公共区域泊车的时间最大不超过14天 在保留3.05米车道宽度的前提下可以在路边上停车（确保消防车可以通过） Wo ist Parken verboten?（禁止泊车区域） Kreuzungen und Einmündungen : 交叉路口和路口前后五米内不能泊车（从道路交叉点算起） Andreaskreuze : 公路与铁道或电车轨道交叉口（X型路标）：市内前后五米内，市外前后五十米内不能泊车 Haltestellen : 停车标志前后15米内不能泊车 Grenzmarkierungen ：边界线标记上禁止泊车 Vorfahrtstraßen ：在建筑区域外具有优先权的街道上禁止泊车 Fahrstreifenbegrenzungen： Bordsteinabsenkungen : 马路牙子理论上不能泊车 Grundstücksein- &amp; ausfahrten : 狭窄的道路上不能泊车 Verkehrsberuhigter Bereich：除非上下车和装卸货物，禁止泊车 Schachtdeckel：窨井盖上不能泊车，仅适用于那些可以在人行道上泊车的区域 Halteverbot : 禁止停车区域也禁止泊车 Halten停车适用于短暂停车（打电话，将信件投放信箱）的情况，时间不超过三分钟，司机不能离开汽车。 基本规则 交通信号灯、铁道口X标志、优先权标志、停车标志十米内禁止停车。 消防车专用道禁止停车 人行横道前5米以及人行横道上禁止停车 Halteverbot Enge und unübersichtliche Straßenstellen Scharfe Kurven Ein- und Ausfädelungsstreifen Bahnübergänge Autobahnen und Kraftfahrstraßen Mit Pfeilen markierte Strecken (z.B. vor Ampeln) Die Fahrbahn eines Kreisverkehrs Taxenstände 相关标志 - -","link":"/2020/01/02/German%20traffic%20regulations-Halten&Parken/"},{"title":"Markdown语法","text":"图片并排显示注意插入图片的代码段放在同一行 123&lt;center class=&quot;half&quot;&gt; &lt;img src=&quot;图片地址&quot; alt=&quot;图片说明&quot; title=&quot;图片标题&quot; width=&quot;50&quot; height=&quot;50&quot;&gt;&lt;img src=&quot;图片地址&quot; alt=&quot;图片说明&quot; title=&quot;图片标题&quot; width=&quot;50&quot; height=&quot;50&quot;&gt;&lt;img src=&quot;图片地址&quot; alt=&quot;图片说明&quot; title=&quot;图片标题&quot; width=&quot;50&quot; height=&quot;50&quot;&gt;&lt;/center&gt; 给图片添加题注1![题注](图片地址) 指定图片的显示大小1&lt;img src=&quot;图片地址&quot; alt=&quot;图片说明&quot; title=&quot;图片标题&quot; width=&quot;50&quot; height=&quot;50&quot; /&gt;","link":"/2020/01/02/Markdown/"},{"title":"目标检测论文笔记","text":"DPM模型：魔改版HOG+SVM论文地址：A Discriminatively Trained, Multiscale, Deformable Part Model Dalal的论文结尾的未来展望部分曾提到，虽然采用固定的模板可以很好的解决的行人检测问题，但是采用可变的部件模型会具有更加普遍的应用场景。也就是本文的主要内容-DPM模型，其全称为可变部件模型。 该模型在首先由图像金字塔生成HOG特征金字塔，并在HOG特征金字塔上的上层采用一个固定的粗略的全局模板，在金字塔的底层采用精细的部件模板。通过这种方法来提高检测的精度。 本文主要贡献 作者提出了一种多尺度的可变部件模型，用于解决通用类别的目标检测问题。 其检测精度比2006 PASCAL的冠军高了两倍，在2007 PASCAL挑战赛的20个类别中，在其中十个类别取得最佳结果。模型处理一张图片速度仅需两秒，现有模型中是最佳的 解决了在困难数据集上，deformable models通常表现不如conceptually weaker models的问题 提出了一种简单有效的策略，可以从弱标记数据中学习部件，其性能可以在单个CPU上三个小时内学习一个模型。 提出了一种新的判别培训的方法 引入了一种新的数据挖掘方法，用于在训练过程中挖掘“hard negative”的实例 系统概述 an object model = 一个全局的 root filter + 几个 part models Part model = a spatial model + a part filter 空间模型(spatial model)定义了一个部件(part)的一组相对于检测窗口的可允许放置位置 检测窗口的score = score of root filter + 部件上的总和 模型概述R-CNN (Region with CNN features)Overfeat = sliding window + CNN architectureRCNN = selective search + CNN architecture 本文主要贡献 一种简单可扩展的检测算法，比VOC 2012最佳结果(DPM HSC)的mAP值高30%（53.3%) 并且RCNN(mAP: 31.4%)在ILSVRC2013数据集的200个类别上性能优于OverFeat(mAP 24.3%)， 原理上的贡献：针对有标签的训练数据稀少的问题，作者发现，在大型辅助数据集上进行有监督的预训练，然后在小型数据集上进行domain-specific的微调是一种很有效的解决办法。 关键点 将高容量的卷积神经网络(CNN)应用于自下而上的region proposal，用来对目标进行定位和分割 当带标签的训练数据不足，则采用有监督的pre-training. 模型概述R-CNN的目标检测系统由三个模块组成： 生成与类别无关的region proposal 一个很大的卷积神经网络，用于从每个区域中提取固定长度的特征向量 一组基于特定类别的线性SVM分类器 Region proposalR-CNN采用selective search为每个图像生成约2k个region proposal。 该方法采用bottom-up grouping和saliency cues的方法来提供准确的任意大小的候选框。 feature extraction在进行特征提取之前，需要对图像进行预处理操作，即将输入图像进行归一化操作，使其大小统一为227*227 classification and localization在分类上，RCNN对每个类别采用训练后的线性SVM分类器进行分类任务。SVM的训练过程分为两步，首先针对特定的类别对线性SVM进行预训练，训练集采用ILSVRC2012。然后采用特定于区域的微调。然后采用该分类器在正区域（目标）和负区域（背景）上进行打分，然后在被打分的区域上进行bounding box regression并使用NMS（greedy non-maximum suppression）进行过滤，以生成保留对象位置的最终边界框。对于标签不足的数据，R-CNN方法中并没有使用无监督的预训练，而是对非常大的辅助数据集ILSVRC进行有监督的预训练，然后进行特定于区域的微调。 SPPnetRCNN虽然在目标检测领域取得了非常优秀结果，但是仍然存在两个问题，首先图像在训练之前必须经过预处理，这会导致图像失真，严重影响检测的精度。其次图像需要对2k个预选框进行卷积运算，这带来了很大的计算负担，对检测的速度也造成很大影响。针对上述的两个问题，何凯明等人提出了SPPnet, 将图像金字塔应用于深度网络，提高了检测的速度和精度。 尽管RCNN在目标检测上取得的成绩是显著的，它仍然存在两个明显的缺点: 在图像被输入到CNN结构中之前，需要对图像进行扭曲变换使图像统一为固定的大小。这两种操作将会导致内容的丢失和失真从而使检测的精度受到影响。 R-CNN采用Selective Search方法从一张图片中生成了约2k个候选区域，在特征提取阶段，CNN网络分别对2k个候选区域做卷积运算，这意味着也就是一张图片需要经过2000次CNN的前向传播，这个过程会产生大量的计算冗余，降低了检测的速度。 **Spatial pyramid pooling: ** 在深度卷积神经网络结构中，卷积层可以处理任意大小的图像，因此对输入图像固定大小的约束仅来自于全连接层。其原因是全连接层的输入必须为固定长度的向量。为了解决这个问题，何等人在CNN的最后一个卷积层和全连接层之的池化层替换为空间金字塔池(如图6)。 空间金字塔池基于bag-of-word【引用】方法，他通过不同的size和stride但数量固定的local spatial bins来提取空间信息。因此无论输入图像的大小，空间金字塔池的输出仅和local spatial bins的数量有关。通过这种方法，不仅可以提高检测的鲁棒性，还可以保证输入图像的尺寸的灵活性，进而也可以改善网络的过拟合问题。 **Feature map computation: ** 针对RCNN网络的第二个缺陷，SPPnet仅从整个输入图像上计算一次特征图，然后在特征图的候选窗口上应用空间金字塔池化。在这里涉及到了一个问题：如何将窗口映射到特征图上？在这篇论文中，作者将窗口的角点映射到特征图上的一个像素上，是图像域中的的这个角点最接近该像素的感受域的中心。这种改进使得SPPnet在Pascal 2007上的检测速度比R-CNN方法快了24-102倍。 Fast RCNN2015年，Girshick et al. 在RCNN和SPPnet的基础上提出了Fast RCNN模型。在这篇论文中，Girshick et al. 系统性的总结了这两种网络的缺点并做出了相应的改进，使得模型的检测速度显著提升，同时也改善了检测的精度。在结果上，Fast RCNN在训练阶段比RCNN快九倍，比SPPnet快3倍。在测试时，检测网络比RCNN快了213倍，比SPPnet快10倍。在实际运行中，检测网络可以可以在0.3秒内处理图像(不包括区域建议时间)，同时在PASCAL VOC 2012上实现了66% mAP。 **ROI Pooling layer: ** 在SPPnet中，何恺明等人采用空间金字塔池化来解决全连接层对图像大小约束的问题。Fast RCNN模型将该SPP层简化为单尺度的ROI(region of interest)层。 RoI层将候选区域划分为大小为H×W的网格，然后在每个网格上采用max-pooling，使得候选区的局部特征映射转变为大小统一的数据。Fast RCNN网络的具有两个数据输入：list of images and list of RoIs in those images 每个ROI具有两个输出： softmax概率和每个边界框的回归偏移。 **Single Stage Training: ** 在R-CNN和SPPnet中，训练的过程遵循多阶段的pipeline, 这主要包括：特征提取的训练, 并采用Log loss对网络进行微调，SVM分类器的训练和Bounding box regression的训练。这中多阶段的训练过程增加目标检测网络的复杂度并影响了检测速度。为了解决这个问题，Fast R-CNN网络采用了单阶段的训练方法。 首先网络采用装备了ROI层的VGG16网络初始化数据，然后采用反向传播对所有的网络权重进行训练。针对SPPnet的SPP层以下无法更新权重的问题，这篇论文采用了分层的采样方法，即针对每个SGD mini-batch 先对图像进行采样，然后对RoIs进行采样，并在同一图像的ROI中共享计算。除此之外，Fast R-CNN还在一次微调中联合优化softmax classifier和bounding box regression。这里Girshick et al.采用了多任务的损失 L：这里L_cls是一个分支softmax层输出概率分布,L_loc是bounding box的损失函数。最终，Fast RCNN将模型整合成为一个整体的单阶段训练模型(除了region proposal), 通过这种方法提高了检测的速度和精度。 Faster RCNNFast R-CNN通过共享卷积和单阶段的训练过程降低了目标检测的运算负担，同时也提高了检测效率和精确度。但是region proposal generation仍然是制约着Region based目标检测模型的一大瓶颈。2015年 Ren et al.在Fast R-CNN基础上提出了Faster R-CNN模型，Instead of Selective, Faster R-CNN通过训练一个全卷积网络来生成目标候选。 该网络被称为Region proposal Network(RPN)。Faster R-CNN将RPN与Fast R-CNN的检测网络整合起来应用于目标检测，最终该模型在Pascal VOC 2007的精确度达到 73.2% mAP(best result for state of the art)。 并且检测的帧率在GPU上达到了5fps。 *Region proposal Network: **为了得到目标提案的矩形框，RPN引入了全卷积网络。网络的输入是任意大小的图像，首先网络先计算出图像的卷积特征图。然后在最后一个卷积层上采用33的滑动窗口同时预测k个区域提案，在这里作者引入了具有平移不变性的锚点概念来描述区域提案，锚点位于滑动窗口的中心，在每个位置采用了3 scales and 3 aspect ratio，yielding k=9的锚点。滑动窗口的输出被映射到一个低维的向量中，该向量将被馈送到回归层和分类层(见图6)。 reg layer得到区域提案的坐标，分类层通过对区域提案进行打分来评估区域中包含物体的概率。为了对RPN网络进行训练，Ren et al.为anchor假设了一个二元的类标签：object/not object。当锚点与ground truth的IoU(Intersection over region)高于0.7或者重叠，则该锚点将会得到一个positiv label(object)。训练所采用的损失函数与Fast R-CNN的相同。 模型训练： RPN网络可以采用back-propagation和stochastic gradient descent进行端对端的训练。在faster R-CNN中，作者通过RPN和检测网络共享卷积层来加快模型的训练和检测速度，但这同时也产生了一个问题，整个faster R-CNN模型在共享卷积层的情况下由于RPN和检测网络的独立训练无法收敛。 在这里作者描述了一种交替优化的四步算法来解决该问题。 首先，算法采用预训练的ImageNet模型对RPN进行初始化，并针对区域建议任务进行端对端的训练。 然后该算法采用RPN生成object proposals, 然后采用fast R-CNN的方法对检测网络进行训练，检测网络也采用ImageNet-pre-trained model进行初始化。 采用第二步训练的检测网络初始化RPN并对RPN进行训练，在此阶段两个网络开始共享卷积层，训练过程仅微调RPN特有的层。 保持共享卷积层不变，再次训练检测网络，训练过程仅微调Fast R-CNN特有的层。 YOLO v12016年，Redmon等人提出的YOLO模型也是目标检测领域的里程碑之一。不同于R-CNN，fast R-CNN，faster R-CNN等两阶段模型，YOLO提出了一种unified architecture用于目标检测。该方法将目标检测的框架视为bounding boxes 和 class probabilities的回归问题，采用单个网络来解决。在检测速度上YOLO展现出了卓越的性能。基础YOLO模型以45帧/秒的速度实时处理图像，作者还采用了一种更加小型的YOLO版本实现了150帧每秒的检测。detection pipeline: YOLO在整副图像上预测所有类别的边界框，首先，输入图像被调整大小为448*448的图像，然后卷积检测网络接收归一化的图像作为输入并输出通过模型的置信度进行打分的边界框。在具体细节上，输入图像首先被划分为 S x S的网格。如果目标的中心点位于某个网格中，则该网格负责目标的边界框的检测。每个网格负责预测B个预测边界框(x, y, w, h)和相应的置信度分数 ####. 除此之外，每个网格还要预测C个条件类别的概率： #### 最终每个图像的预测输出可以参数化为一个S x S x (B x 5 + C)的tensor (见下图). **Network training: ** YOLO所采用的检测网络由24个卷积层和两个全连接层组成，为了提高检测的精度，网络的卷积层采用ImageNet 1000-class competition dataset进行预训练。模型的最后一层输出目标的bounding box和class probabilities。在模型激活函数上模型的最后一层采用了线性的激活函数，其它层采用了leaky rectified linear activation。在优化问题上，YOLO采用了sum-squared error优化模型的输出，正如下面的激活函数所展示的： 在这里l_{i}^{obj}代表网络i中存在对象，l_{ij}^{obj}代表网络i的第j个bounding box中存在对象. 模型详细解释：yolo v1详解 YOLO v2尽管Redmon等人提出的YOLO在目标检测的速度上取得很大的突破，但该网络仍然存在诸多限制。 由于边界框预测的空间约束，每个网格单元只预测两个含有有单个类别的bounding box，这在提高了检测速度的同时也降低了对多个成组出现的小物体的检测能力。 模型的检测精度不够高，略低于Faster R-CNN(见表格) 检测网络中的多个下采样层导致了图像信息的丢失，所提取的模型特征不够精细。针对以上问题，YOLOv2相对v1版本，采用了多种方法在预测精度，检测速度和识别对象种类三个方面进行了改进。除此之外，作者还提出了一种多尺度的训练方法，使模型可以在速度和准确性之间做出权衡。结果上，YOLO V2以67FPS的速度运行时，在VOC 2007上的mAP值为76.8%，而以40FPS的速度运行时的mAP值为78.6%。由于YOLO v2模型能够检测9000种不同对象，因此该模型被称为YOLO9000。 Better: 针对模型的第一个缺点，Redmon et al.采用不同的方法来改进YOLO模型。首先作者在所有的卷积层上采用了batch normalization来解决反向传播过程中的梯度消失和梯度爆炸问题，并且可以对模型进行规范化，从而能够获得更好的收敛速度和收敛效果。其次，YOLO v2在分类器预训练后，再采用的高分辨率样本对分类器进行微调，这样可以避免缓解了分辨率突然切换造成的影响。然后，YOLO模型移除了全连接层并引入了anchor来预测边界框。通过该方法来提高模型的召回率。然后，在锚点框的使用上，YOLO v2在训练集的真实框上使用k-means clustering来得到先验框的尺度。但使用锚定框会遇到位置的预测不稳定的问题，这里Redmon et al. 通过添加约束的方法，将预测的中心限制在特定网格单元中。对于YOLO v1模型所提取的特征过于粗糙的问题，YOLO v2引入了一个新的passthrough层检测细粒度特征。具体来说，passthrough层通过将相邻要素堆叠到不同的通道中过来将高分辨率的特征和低分辨率的特征连接起来。使图像的细节信息尽可能的被保留下来。在模型的训练上，由于YOLO网络上去掉了全连接层，因此网络可以处理任意大小的图像。为了保证图像对不同尺度的图像的检测精度，YOLO v2在训练过程中采用不同尺度的图像进行训练，网络的每10个批次将会随机选择新的图像尺寸。最终使网络能够适应各种大小的目标的检测。 **Faster: **为了进一步提升速度，YOLO2提出了Darknet-19（有19个卷积层和5个MaxPooling层）网络结构。DarkNet-19比VGG-16小一些，精度不弱于VGG-16，但浮点运算量减少到约1/5，以保证更快的运算速度。 **Stronger: ** one stage model vs. two stage model如下图所示，当我们对检测的管线进行横向比较时，可以很清楚的看到技术的发展趋势。在传统目标检测阶段，检测的pipeline分为三步：区域选择，特征提取和分类。在此阶段检测算法的特征是基于规则手工设计的。在基于深度学习的目标检测阶段，两阶段模型仍遵循传统的目标检测方法的思路，将深度学习技术整合入目标检测的pipeline中。正如图三所示，在R-CNN，SPPnet和Fast R-CNN中，检测模型引入卷积神经网络来提取图像特征，在Faster R-CNN中，卷积神经网络被同时应用于候选区域生成和检测阶段，通过共享卷积使整个检测模型被统一整合为完整的深度学习模型。而基于回归的单阶段检测模型则采用新的思路，直接采用深度学习技术从pixel直接预测物体，取消了区域生成的阶段，大大简化了模型的复杂程度。","link":"/2020/01/15/Note_for_object_detection/"},{"title":"Hueman主题的折腾之路","text":"Hueman主题的安装虽然网上各种博客的教程大多使用的都是Next主题，但是个人审美上还是对Next的风格接受不能，Hueman才是我心目中的博客风格应有的样子。下面就介绍一下Hueman主题的使用步骤： 手动下载Hueman主题，或者将主题Clone到本地 ../themes 目录下 git clone https://github.com/ppoffice/hexo-theme-hueman.git 在Hexo文件目录下打开**_config.xml文件，找到关键词 theme 将主题名称修改为：hexo-theme-hueman** 在\\Hexo\\themes\\hexo-theme-hueman目录下找到**_config.xml.example文件，将后缀.example**去掉 在Hexo文件目录下打开git bash，依次执行 git clean 和 git g -d，将Hueman主题成功提交到Gitpage. 打开博客网址即可看到主题效果。 Hueman主题基本配置theme: 后面改为hueman 修改语言language: 后面改为zh-CN 修改title这个会在你主页上，显示在浏览器框中的网页名称 修改subtitle副标题博客logo边上的文字说明 修改authorauthor: 后面添加你自己的名字（这个将在网页的底部显示） 添加about页面在Hexo文件目录下的打开git bash 输入以下代码： hexo new page &quot;about&quot; 评论系统Hueman支持多种评论系统，但有些目前已经停止服务，有些在国内被墙了，比如以前很喜欢用disqus，可惜国内并不支持。最近发现gitalk比较好用，因此打算将评论系统改成gitalk。 Hueman主题下配置Gitalk在Hueman主题下配置Gitalk的基本方法如下： 设置github认证： 登陆github, 在个人账号下选择Setting, 然后选择developer setting, 接着选择OAuth Apps在该界面下选择新建Github App.其中Homepage URL和Authorization callback URL都必须是一样的，比如我个人github的博客地址https://andrelyl.github.io/ 。然后点击保存，记下Client ID和 Client Secret。 打开Hueman的主题配置文件_config.yml，在gitalk部分填写相关信息： 1234567gitalk: on: true owner: # Github user name repo: # url个人博客的 client_id: # 上一步得到的Client ID client_secret: # 填写上一步得到的Client Secret admin: # GitHub repo owner and collaborators who can initialize github issues 部署到Github上","link":"/2019/12/28/Theme_hueman/"},{"title":"第一篇博客","text":"Hello, World! 我是安德烈 这是我的第一篇博客。 本博客基于HEXO框架搭建，主题为Hueman，博客的搭建参考了掘金的一篇博客搭建教程：2018，你该搭建自己的博客了 为什么要写博客我认为博客的价值在于：首先，写博客的过程可以让你静下心来思考，让你能够更加清醒的了解自己和找到自己的定位；每个人都会有迷茫的时候，找不到自己接下来人生的方向，现实总是不那么如人意，不知道路在何方。写博客的过程可以 帮助你静下心来去思考，重新认识自己。 其次，写博客也是一种很好的学习手段。写博客的过程不仅仅是做笔记，同时也是对所得知识融入自己的思考的再加工过程，可以加深对知识理解程度，记录学习知识过程中的所思，所惑，所得，对日后的回顾也有所裨益。 再者，博客也是一个分享idea，交流技术的平台。不仅有助于他人，更可以技会友。 关于我无名之辈，留学于德国，专注于自动驾驶 专业相关 自动驾驶 计算机视觉 嵌入式开发 机器人技术 爱好相关 航拍 DIY 跑步 其他分享笑话一则：杨一笑殁，葬云梦泽西鹿鸣山，其碑志曰：初从文，三年不中；后习武，校场发一矢，中鼓吏，逐之出；遂学医，有所成。自撰一良方，服之，卒。","link":"/2019/02/19/first_blog/"},{"title":"基于鸟瞰图的点云目标检测：Birdnet+","text":"简介自动驾驶汽车中的车载3D对象检测通常依赖于LiDAR设备捕获的几何信息。尽管通常优选使用图像特征进行检测，但是许多方法仅将空间数据作为输入。利用这些信息进行推理通常涉及使用紧凑的表示形式，例如鸟瞰图（BEV）投影，这会导致信息丢失，从而阻碍了对象3D框的所有参数的联合推理。在本文中，作者提出了一个完整的端到端3D对象检测框架，该框架可以通过使用两阶段对象检测器和临时回归分支仅从BEV图像中推断出定向3D框，从而无需进行后处理阶段。该方法在很大程度上优于其前身（BirdNet），并在KITTI 3D对象检测基准测试中获得了评估中所有类别的最新结果。 核心思想：通过将点云数据投影为BEV表示将3D目标检测任务转化为2D图像检测问题，然后采用两阶段的Faster RCNN模型实现检测任务。 技术细节： BEV 表示: 将LIDAR点云数据编码成3个通道的2D结构，这三个通道为： 最大高度(&lt; 3m)，平均强度和单元格中的归一化点密度。 编码不包括每个单元的最低点信息（groud truth） ROI 区域：前左右35m范围 单元网格的大小：每个单元网格的大小为5cm 特征提取： 采用ResNet-50网络，为了解决BEV视图下行人难以检测的问题，作者对ResNet-50做了一些修改：(i)采用conv3 layer, 下采样因子设为8(ii) 利用特征金字塔网络(FPN)一边从每个ResNet块的输出中提取每个对象对应的特征 Region Proposal: anchor尺寸：1616， 4848， 80*80 anchor长宽比： 1:1, 1:2, 2:1 anchor是轴对齐的 Feature pooling分辨率： 7*7 Classfication &amp; Bounding box regression RPN的第一阶段的proposals采用BEV图上的2D bounding box来表示，第二阶段负责对这些proposals进行分类。 预测步骤由两个全连接层完成， 每个层具有1024个元素，这些元素最终被馈送到一组individual heads中, 每个head由FC层组成并负责不同的任务，这些heads有三个分支，分别负责分类，轴对齐的框回归和离散的yaw的分类","link":"/2020/04/03/paper_birdnet/"},{"title":"目标检测之方法论","text":"摘要目标检测是近些年来计算机视觉和数字图像处理的一个研究热点，它是图像处理和计算机视觉学科的重要分支，广泛应用于自动驾驶，机器人导航、智能视频监控、工业检测、航空航天等诸多领域。它的主要任务是检测已知的类别在图像中的实例，它包含物体定位和物体分类两个子任务，同时确定物体的类别和位置。传统的的目标检测算法通过区域选择，特征提取，分类三个步骤实现对物体的检测。随着深度学习技术的发展，目标检测算法采用不同的深度学习网络来提高目标检测技术的速度和准确度。它可以分为 one stage, two stage 和 multi stage 三种类别。在这里本文主要回顾了目标检测的经典算法, 主要包括R-CNN, Fast R-CNN, Faster R-CNN。并采用已知的数据对这些算法的识别速度和检测精度进行了横向比较，并总结了不同算法的特点和应用范围。 概述另一方面，由于卷积神经网络在目标检测领域的应用，使得基于深度学习的目标检测方法在近些年来发展十分迅速。2013年，Ross Girshick等人提出了R-CNN网络，首次CNN方法引入目标检测领域，大大提高了目标检测效果，同时改变了目标检测领域的主要研究思路。2015年， 传统目标检测方法区域选择：特征提取：分类：分类的目的是将图片用一种层次化的方法进行表述。在上一步中所提取的候选区域的特征将被送到分类器，分类器采用适当的算法对其进行分类，用事先确定好的类别和实例ID来描述图片。传统目标检测采用的分类器算法有：SVM，Adaboost，DPM等。 根据目标检测具体的应用场景，研究人员对以上三个步骤的具体算法做了各种各样的改进，以实现更高的准确率与更快检测速度。 在过去的20年里，研究人员在传统目标检测领域做了很多的研究，提出了一些可以看做里程碑式的经典算法，如图二所示，接下来我们将按照时间顺序介绍一些传统目标检测领域的重要算法。 Haar-like特征 + Adaboost2001年，Viola和Jones提出了用于人脸识别的目标检测算法，这种算法大大提高了人脸检测的效率和精度。该算法主要基于三个重要步骤：Haar-like特征，Adaboost分类和Cascade级联分类器 论文采用了最简单的矩形特征作为Feature descripter, 作者创新性的提出了积分图的概念。该图像和原图像大小相同，其每个位置的值为像素点左上所有像素点之和。 采用这张积分图，使得计算任意矩形区域的特征值的运算可以通过矩形框四角的所对应的值相加减得到（见图2） 首先论文采用了哈尔矩形特征作为Feature descripter. 该特征通过计算矩形明暗区域的像素和差值来描述区域的特征。作者创新性的提出了积分图的方法来简化运算，该图像和原图像大小相同，其每个位置的值为像素点左上所有像素点之和。 采用该图可以使任意矩形区域的特征值通过积分图上矩形四个顶点的值进行运算，这大大降低了计算负担。其次， HoG + SVMHOG descripter是传统目标检测领域的重要的里程碑，它在SIFT，和形状上下文的基础上，在均匀建个的单元格密集网络上使用 特征提取链： 输入图像首先被分成许多小的空间区域（616像素块，四个 88 的像素单元），通过收集像素中每个像素的梯度和边缘方向 可以计算一维面向梯度的直方图。 但是由于局部照明的差异以及前景和背景的对比度，梯度强度变化的范围非常大，因此需要对梯度的局部对比度进行归一化。 需要进行对比度归一化的步骤，以使描述符对光照，阴影和边缘变化具有鲁棒性。 然后，将规范化描述符（HOG描述符）填充到密集网格中的检测窗口中，并将由HOG描述符形成的特征向量放入线性SVM分类器中以实现二进制分类。 最后，检测窗口扫描输入图像的多尺度图像金字塔，通过非最大抑制来检测物体。在分类器的训练过程中，dalal等人采用一个两步的训练方法，使得误检率减少了5% 。 DPM + LSVM值得一提的是，Dalal的论文所提出的HOG+SVM方法采用固定的模板来提取HOG特征，这种方法对于无法处理目标的形变问题。 2008年，P. Felzenswalb在HOG特征的基础上提出了DPM+LSVM的方法，这种方法在由HOG特征生成的金字塔上，采用一个粗略的模板来涵盖物体，和一个精细的模板来检测物体的可形变部分。 通过这种方法，作者在2007 PASCAL挑战赛的20个类别中的十个类别获得最佳结果。并且检测精度是2006 PASCAL冠军的两倍。作者也因此在2010年获得 PASCAL VOC的终身成就奖 **系统概述: **基于滑动窗口法，该目标检测系统由一个root filter和多个part models组成. 基于深度学习的目标检测方法1998年，Yann LeCun提出了LeNet-5的网络结构，该结构可以端到端训练模型以进行文档检测。 它成为最经典的CNN结构，以后的大部分CNN模型都源自此版本。 2012年，Kriszhevsky等人在物体检测领域采用了基于CNN的方法。 在2014年，Ross Girshick等人。 提出的R-CNN，其出色的性能吸引了研究人员的注意。 从那时起，深度学习成为对象检测领域的一个热点。 与具有手工功能的传统方法相比，基于CNN的方法可以更分层和更深入地表示特征。 典型的CNN结构由具有特征图的许多层组成。 特征图中的像素（神经元）通过权重连接到先前的特征图。 可以通过具有共享权重的卷积核从上一层的局部区域中获取每一层的特征。 输入图像将在网络中重复计算，低级特征将在初始层中计算，而高级特征则可在后续层中提取。 结果上，模型的表达能力将通过CNN结构得到了指数级的提高。 特征可以以较高的语义层面来表达。 随着研究的不断深入，基于深度学习的方法发展出了两种不同的方向。 第一种是以RCNN, Fast RCNN，Faster RCNN为代表的两阶段模型(two stage frameworks)，又称作基于区域模型(region based frameworks)。该方法遵循传统的目标检测流程，首先生成候选区域(region proposal)，然后根据所提取的特征将这些候选区域分为不同的类别。 第二种是基于分类/回归的一步框架，它可以直接从图像的像素映射到边界框坐标和类别的概率。通过这种方法可以大大降低时间开销。其代表模型有： Yolo, SSD。 One stage Model随着上一小节提到的RCNN，Fast R-CNN, Faster R-CNN等论文对两阶段模型的潜力的发掘，两阶段模型的检测精度不断的提高。 但同时由于两阶段模型需要先生成区域候选的步骤，其检测速度成为了限制其性能的瓶颈，并且由于其计算成本的问题，使其也难以应用到性能比较中庸的穿戴设备或移动设备中去。 为了解决这一问题，研究人员提出了一种新的统一的检测架构，其不同于two Stage modeld的架构，该统一架构的不需要生成区域预选，直接从整幅图像上预测目标的边界框坐标和类别概率。通过这种方法大大提高了检测的速度。该架构被称作One Stage Model. R-CNN在R-CNN出现之前，最成功的目标检测模型是DPM，其在VOC数据集上的最佳表现是mAP 34.3%左右，但是Ross Girshick在2013年提出的R-CNN方法将这个","link":"/2019/12/30/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%96%B9%E6%B3%95/"},{"title":"算法：判断质数","text":"质数定义：指在大于1的自然数中，除了1和该数自身外，无法被其他自然数整除的数（也可定义为只有1与该数本身两个正因数的数）。 思路1：定义根据定义，采用2到n-1中的每一个数去除n，如果不能被整除，则该数为质数。时间复杂度：O(n)。 123456789101112bool is_prime(int n){ bool isprime = true; for(int i=2; i &lt; n; i++){ if(n % i==0){ isprime=false; break; } } return isprime;} 思路2：质数筛选定理质数筛选定理： 如果n不能够被不大于根号n的任何质数整除，则n是一个质数。参考链接： https://zhuanlan.zhihu.com/p/100051075 https://blog.csdn.net/wo17fang/article/details/47656769 1234567891011bool is_prime(int n){ bool isprime= true; int max = static_cast&lt;int&gt;(sqrt(n)); \\\\隐式类型转换 for(int j=2; j&lt;=max; j++){ if(n%j == 0){ isprime=false; break; } } return isprime;}","link":"/2021/01/25/Algorithm/001.is_prime/"},{"title":"排序算法","text":"基本概念排序算法是程序设计中最基本的算法，常用的排序算法有十种，可以分为内部排序和外部排序两种类型： 内部排序 内部排序是指待排序列完全存放在内存中所进行的排序过程，适合不太大的元素序列。 常见的内部排序算法：冒泡排序，快速排序，插入排序，选择排序，希尔排序，堆排序。 外部排序 外部排序是针对于极大量数据的排序算法，由于数据无法一次放入内存，算法采用“排序-归并” 策略，首先将部分数据依次读入内存，排序后生成有序的临时文件，在归并阶段将这些临时文件组成较大的有序文件。 常见的外部排序算法有归并排序，计数排序，桶排序，基数排序。 关于排序算法的简单介绍： 排序算法的稳定性如果两个具有相同键的对象在输入输出中的顺序与在输入未排序数组中出现的顺序相同，则该排序算法被认为是稳定的。有些排序算法本质上是稳定的，例如插入排序，合并排序，冒泡排序等。而有些排序算法则不是，例如堆排序，快速排序等。 但是，任何给定的不稳定算法都可以修改为稳定。可以使用特定的排序算法来使其稳定，但是通常，可以通过更改键比较操作将本质上不稳定的任何基于比较的排序算法修改为稳定，以便将两个键的比较视为位置。具有相同键的对象的系数。参考文献 冒泡排序冒泡排序（Bubble Sort）重复遍历要排序的数列，一次比较两个元素，如果他们的顺序错误就把他们交换过来。 重复地进行直到没有再需要交换，也就是说该数列已经排序完成。算法步骤： 以升序为例，比较相邻两个元素大小，如果第一个元素大于第二个，则交换两个元素，否则不做改变。 从数组的第一个元素开始，遍历到数组的倒数第二个元素。 代码实现： 123456789101112131415161718192021222324#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;void bubble_sort(vector&lt;int&gt; &amp;num, int len){ for(int i = 0; i &lt; len-1; i++){ for(int j = 0; j&lt;len-1-i; j++){ if(num[j] &gt; num[j+1]) swap(num[j], num[j+1]); } }}int main(){ vector&lt;int&gt; num= { 61, 17, 29, 22, 34, 60, 72, 21, 50, 1, 62 }; int len = num.size(); for(int i=0; i &lt; len; i++) cout &lt;&lt; num[i] &lt;&lt; ' '; cout &lt;&lt; '\\n'; Bubble_sort(num, len); for(int i=0; i &lt; len; i++) cout &lt;&lt; num[i] &lt;&lt; ' '; return 0;} 选择排序选择排序的方法为第一次从待排序的数据元素中选出最小（或最大）的一个元素，存放在序列的起始位置，然后再从剩余的未排序元素中寻找到最小（大）元素，然后放到已排序的序列的末尾。 以此类推，直到全部待排序的数据元素的个数为零。 选择排序是不稳定的排序方法。算法步骤： 记录数据中的第一个元素的index 遍历数据并与该元素进行比较，如果小于该元素则更新index，完成遍历后交换第一个元素和index所指向的最小值。 重复以上步骤直至完成排序。 代码实现： 123456789101112void selection_sort(vector&lt;int&gt; &amp;num, int len){ int min; for(int i=0; i&lt;len; i++){ min = i; for(int j=i; j&lt;len; j++){ if(num[j] &lt; num[min]) min = j; } swap(num[i], num[min]); }} 插入排序将第一待排序序列第一个元素看做一个有序序列，把第二个元素到最后一个元素当成是未排序序列。从头到尾依次扫描未排序序列，将扫描到的每个元素插入有序序列的适当位置。（如果待插入的元素与有序序列中的某个元素相等，则将待插入元素插入到相等元素的后面。） 代码实现： 12345678910void intersection_sort(vector&lt;int&gt; &amp;num, int len){ for(int i=1; i&lt;len; i++){ for(int j=i; j&gt;0; j--){ if(num[j] &lt; num[j-1]) swap(num[j-1], num[j]); } }} 希尔排序希尔排序（Shellsort），也称递减增量排序算法，是插入排序的一种更高效的改进版本。希尔排序是非稳定排序算法。希尔排序是基于插入排序的以下两点性质而提出改进方法的： 插入排序在对几乎已经排好序的数据操作时，效率高，即可以达到线性排序的效率 但插入排序一般来说是低效的，因为插入排序每次只能将数据移动一位希尔排序原理的视频介绍：希尔排序 算法实现： 12345678910void shell_sort(vector&lt;int&gt; &amp;num, int len){ for(int gap = len / 2; gap &gt; 0; gap /= 2) for(int i = gap; i &lt; len; i++){ int temp = num[i]; int j = i; for( ; j &gt;= gap &amp;&amp; temp &lt; num[j-gap]; j-=gap) num[j] = num[j-gap]; num[j] = temp; }} 快速排序快速排序是在实践中最快的已知排序算法，算法的平均运行时间是O(NlogN), 最坏的性能为O(N^2).算法步骤： 从数列中随机挑出一个元素，称为 “基准”（pivot）; 重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区退出之后，该基准就处于数列的中间位置。这个称为分区（partition）操作； 递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序； 算法实现： 1 归并排序归并排序（Merge sort）是建立在归并操作上的一种有效的排序算法。该算法是采用分治法（Divide and Conquer）的一个非常典型的应用。 作为一种典型的分而治之思想的算法应用，归并排序的实现由两种方法： 自上而下的递归（所有递归的方法都可以用迭代重写，所以就有了第 2 种方法）； 自下而上的迭代； 和选择排序一样，归并排序的性能不受输入数据的影响，但表现比选择排序好的多，因为始终都是 O(nlogn) 的时间复杂度。代价是需要额外的内存空间。 算法步骤： 申请空间，使其大小为两个已经排序序列之和，该空间用来存放合并后的序列； 设定两个指针，最初位置分别为两个已经排序序列的起始位置； 比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置； 重复步骤 3 直到某一指针达到序列尾； 将另一序列剩下的所有元素直接复制到合并序列尾 参考资料：[1] 关于排序算法的一点知识——实例和伪代码[2]","link":"/2021/01/25/Algorithm/002.algorithm_sorting/"},{"title":"C++：vector容器","text":"二维向量的遍历方法123456789//二维向量的遍历，迭代器遍历vector&lt;vector&lt;int&gt; &gt; array = {{1,2,8,9},{2,4,9,12},{4,7,10,13},{6,8,11,15}}; vector&lt;vector&lt;int &gt;&gt;::iterator iter;for (iter = array.begin(); iter != array.end() ; ++iter) { for (int i = 0; i &lt; (*iter).size(); ++i) { cout &lt;&lt; (*iter)[i] &lt;&lt; &quot; &quot; ; } cout &lt;&lt; endl;} 123456789//二维向量的遍历，数组下表vector&lt;vector&lt;int&gt; &gt; array = {{1,2,8,9},{2,4,9,12},{4,7,10,13},{6,8,11,15}}; for (int i = 0; i &lt; array.size(); i++){ for(int j = 0; j &lt; array[i].size(); j++) cout &lt;&lt; V[i][j] &lt;&lt; &quot; &quot;; cout &lt;&lt; endl;}","link":"/2021/02/06/Algorithm/003.vector_cplusplus/"},{"title":"Minecraft-布伦图书馆模型","text":"最近特别热衷于Minecraft这个游戏，在这个马赛克的世界里，在里面造一些奇奇怪怪的建筑还是蛮有成就感的。最近突发奇想，把布伦的小图书馆在Minecraft里复原出来，故有此篇。 基本思路在图书馆网站上找到了每个楼层的简易平面图，准备用这几张图来确定基本的尺寸和比例。为了保证尺寸的合理性。打算采用平面图的像素大小来确定长宽。具体方法是用PS来测量图片上的长宽像素量，然后采用14*14大小的像素块来进行栅格化。由于平面图上面没有每层的高度信息，于是我目测了图书馆每层的高度后，结合MC中建家的经验将图书馆每层高度栅格化为6格，每层地面厚度为两格。其基本元素规则定义如下： 栏杆：黑色玻璃板， 桌子：白色地毯加栅栏 光源：萤石，嵌入地面层的底层来提供照明 - - -","link":"/2020/02/11/Hobby/Minecraft-Bibliothek/"},{"title":"Arduino超声波雷达","text":"超声波雷达","link":"/2019/03/01/Hobby/%E8%B6%85%E5%A3%B0%E6%B3%A2%E9%9B%B7%E8%BE%BE/"},{"title":"树莓派延时摄影","text":"树莓派延时摄影演示视频","link":"/2019/02/20/Hobby/%E6%A0%91%E8%8E%93%E6%B4%BE%E5%BB%B6%E6%97%B6%E6%91%84%E5%BD%B1/"},{"title":"大学时光纪念-雪中石大360全景","text":"360全景图–石大雪景","link":"/2019/02/20/Hobby/%E9%9B%AA%E4%B8%AD%E7%9F%B3%E5%A4%A7360%E5%85%A8%E6%99%AF/"},{"title":"大学时光纪念-青岛","text":"航拍照","link":"/2019/02/20/Hobby/%E9%9D%92%E5%B2%9B%E8%88%AA%E6%8B%8D%E7%85%A7/"},{"title":"Tensorflow入门_Udacity","text":"Cha1： Hello World基本术语 人工智能：一种计算机科学分支，旨在让计算机达到人类的智慧。实现这一目标有很多方式，包括机器学习和深度学习。 机器学习：一系列相关技术，用于训练计算机执行特定的任务。 神经网络：一种机器学习结构，灵感来自人类大脑的神经元网络。神经网络是深度学习的基本概念。 深度学习：机器学习的一个分支，利用多层神经网络实现目标。通常“机器学习”和“深度学习”可以相互指代。 机器学习算法应用 游戏： AlphaGo- Google DeepMind团队 医疗： 采用机器学习算法检测皮肤癌等，精度与人类专家相当 自动驾驶： … Tensorflow Tensorflow Lite: 可以在Android和iOS设备上创建移动应用 Tensorflow.js: 可以在网络浏览器中运行相应的应用 Tensorflow实现语言： Python, JavaScript, Swift, R, Julia等。但目前，Python和JavaScript是最完整的实现语言。 Tensorflow开发环境： 本课程采用python和Google的开发环境Colab(类似于Jupyter Notebook，Colab采用交互式Notebook进行Python开发，程序在Google Cloud上托管，因此不需要配置软件环境，仅需在网络浏览器上使用) 练习：Python和Colab初级知识 个人练习: https://github.com/AndreLYL/Tensorflow-learning/blob/master/Tensorflow_Udacity_tutorial_01.ipynb Cha2： 机器学习简介Sebastian访谈大佬告诉我们机器学习比计算机编程要简单，所以我们要相信大佬，大胆的去做吧，奥利给！ 传统算法和机器学习算法区别 机器学习术语 特征：模型的输入 样本：用于训练流程的输入/输出对 标签：模型的输出 层级：神经网络中相互连接的节点集合。 模型：神经网络的表示法 **密集全连接层 (FC)**：一个层级中的每个节点都与上个层级中的每个节点相连。 权重和偏差：模型的内部变量 损失：期望输出和真实输出之间的差值 MSE：均方误差，一种损失函数，它会将一小部分很大的差值视作比大量很小的差值更糟糕。 梯度下降法：每次小幅调整内部变量，从而逐渐降低损失函数的算法。 优化器：梯度下降法的一种具体实现方法。（有很多算法。在这门课程中，我们将仅使用“Adam”优化器，它是 ADAptive with Momentum 的简称，并且被视为最佳优化器。） 学习速率：梯度下降过程中的损失改进“步长”。 批次：在训练神经网络的过程中使用的一组样本。 周期：完全经过整个训练数据集一轮 前向传播：根据输入计算输出值 反向传播：根据优化器算法计算内部变量的调整幅度，从输出层级开始，并往回计算每个层级，直到抵达输入层。 练习：摄氏度转化为华氏温度 小结：https://classroom.udacity.com/courses/ud187/lessons/e0c70c77-5584-4f83-a47b-a67a6172ae75/concepts/ac6c6991-8096-4c7a-bad1-706f7e3d36f1 练习讲解：https://colab.research.google.com/drive/1vQ9mRFDeeFaP8u1LE6UiYbpF-qBRe5Fb 个人批注：https://github.com/AndreLYL/Tensorflow-learning/blob/master/Tensorflow_Udacity_tutorial_02.ipynb 密集层 （Dense Layer）密集层也叫全连接层，即一个层级的每一个节点都与上一个层级的所有节点相连。 上图的全连接层在Tensorflow中可以用以下代码实现： 123hidden = keras.layers.Dense(units=2, input_shape=[3])output = keras.layers.Dense(units=1)model = tf.keras.Sequential([hidden, output]) 训练的流程是指讲权重和偏差调整为最佳值，使模型能够将输入和输出相匹配。但训练过程只改变w和b，并不改变模型，即下图中的数学公式。(w: 权重 b: 偏差) Cha3： 首个模型 - Fashion MNISTSebastian访谈问： 未来十年内，哪些前沿性科技和挑战对深度学习的影响最大？未来最重要的挑战是什么？答： 其一通用人工智能，其二贴合市场 Fashion MNISTFashion MNIST是一个数据集,该数据集由28*28像素的灰度服饰图像组成，共70000张图像，下图是其所包含的所有服饰标签的完整列表： 神经网络相关术语： 扁平化：将二维图像转换为一维向量的过程 ReLU：一种激活函数，使模型能够解决非线性问题 Softmax：一种函数，能够为每个潜在输出类别生成概率 分类：一种机器学习模型，用于区分两个或多个输出类别 ** ReLU函数（修正线性单元）**ReLU 是一种激活函数。激活函数有好几种，例如 ReLU、Sigmoid、双曲正切、ELU，但是 ReLU 是最常用的激活函数，通常默认都设为 ReLU。该函数如下图所示，其特性为：如果输入是附属或0，则函数输出为0, 如果输入是正数， 那么输出将等于输入。ReLU使网络能够解决非线性问题，在实际问题中，其大多都为非线性问题。在这种情况下，向密集层添加ReLU有助于解决问题。扩展阅读 本章节的神经网络模型如下图所示： **Input image:**上面提到，Fashion MNIST数据集中的图像大小均为28 * 28 = 784像素，并且神经网络的输入必须是向量，因此需要将图像转化为以为数组，该过程即为扁平化，其实现代码为: tf.keras.layers.Flatten(input_shape=(28,28,1)) 密集层：输入将和密集层完全连接，该密集层共128个单元，在这里需要激活函数，其实现代码为：输出层：输出层共有10个单元，因为该数据集总共有10个类别，在这里每张图片的预测结果应为图像在每个类别中的概率大小，其和为1。（对于任何一个分类神经网络，最后都会添加一个密集层，其包含的单元数量和类别数量一样，并且始终会添加softmax语句） 训练和测试数据集通常会划分为不同的子集，如训练集和测试集，用于训练神经网络和测试神经网络的最终效果。通过测试数据集，我们可以使用网络从未见过的数据测试网络。这样我们便能检测模型的泛化程度，即泛化到训练期间未见过的数据的效果，而不是仅仅记住训练样本。同样，我们通常会使用验证数据集。此类数据集不用于训练，而是在训练期间用于测试模型。我们在一定的训练步数之后使用验证集，判断训练进展如何。例如，如果在训练过程中损失降低了，但是验证集的准确率下降了，则表明模型在记住测试集。训练完毕时，也会使用验证集衡量模型的最终准确率。 扩展阅读：Google 机器学习速成课程的训练和测试集部分当有一个很大的数据集合，一部分用于训练一部分用于测试，测试集的选择需要注意随机化处理，一般训练集越大，训练出的模型越精确，测试集越大，对评估指标的信心越充足，置信区间就越窄。 如果数据集规模比较大，则取其10% ~ 15%就可以得到良好的验证效果，如果数据集比较小，则验证阶段就需要交叉验证等复杂操作。典型陷阱：不要将用于测试的集合同时用于训练，这样会得出非常优秀的结果（如测试准确率100%）。 Code总结 epochs: epochs的参数对模型的精度有直接的影响，周期数过小，模型欠拟合，精度不够。周期数过大，模型过拟合，在训练集精度很高，在测试集上训练精度很低. 密集层神经元数量： 神经元过少会明显减小检测的精度，总体上来说，神经元增加会增加会提升精度（根据源码中的练习得出的不完全实验结论） 增加网络层数 玄学： 官方教程的源码和我的源码的结果差别很大，其一在于同样的参数我的模型最终精度会比课程给的源码的精度低一些。关键我还是按照官方给的代码手打的，而且课程给的参考源码有明显错误，比如模型的输出层没有使用softmax。 个人练习： https://colab.research.google.com/drive/1ItgEKIIG55Mc11dpgTQFLMJ-cvMmSnNX#scrollTo=z4Ji8sEmR4YH课程源码： https://colab.research.google.com/drive/1RV1-alG87M8JWnMU0NaytOGHsieRq9-I#scrollTo=9ODch-OFCaW4 本章总结机器学习的需要解决的问题主要由两个类别：递归问题和分类问题 Regression： 输出一个值的模型。例如，估算房屋价值。 Classfication： 一种模型，能够输出多个类别的概率分布。例如在 Fashion MNIST 模型中，输出是 10 个概率，每种服饰对应一个概率。我们在最后的密集层中使用 Softmax 激活函数创建了这个概率分布。 # Cha4: CNNSebastian访谈问：CNN特点答：具有不变性，结构重复性，CNN的流行不是由于算法的变革，而是大数据问：未来应用领域答：图像，语言领域 CNN简介卷积神经网络两个最重要的概念就是卷积(Convolutions)和最大池化(MaxPooling)卷积: 卷积的运算如下图所示，简单来说就是窗口中的每个pixel的值与卷积核中相应位置的核素相乘，最后将所有的值相加放在居中位置。在这里涉及到边缘像素处理问题，有两种处理方式，其一是将边缘的像素舍弃，但这会造成信息丢失问题；其二是将原图像边缘补0，然后再进行卷积运算。最大池化: 最大池化是指通过总结区域减小输入图像大小的流程，如下图所示，最大池化设计两个主要参数：网格(pool size)和步长(stride). 最大池化的过程是找出网格中的pixel最大值并放在新的图像中的相应位置，步长代表窗口的滑动距离，下图中的步长为2。 MaxPooling的过程也叫做下采样。 小结： 卷积是指向图像应用滤波器（核）的过程。最大池化是指通过下采样降低图像大小的过程。在 Keras 中使用 Conv2D 层级类型向神经网络模型中添加卷积层。此层级与密集层类似，并且需要将权重和偏差调整为合适的值。Conv2D 层级也有核（滤波器），我们也需要调整这些滤波器的值。在 Conv2D 层级中，我们将调整滤波器矩阵中的值，从而生成正确的输出。 术语： CNN： 卷积神经网络。即至少有一个卷积层的网络。典型的 CNN 还包括其他类型的层级，例如池化层和密集层。 卷积： 向图像应用核（滤波器）的过程 核/滤波器： 小于输入的矩阵，用于将输入变成多个小区域 填充： 在输入图像周围添加像素，像素值通常为 0 池化： 通过下采样降低图像大小的过程。池化层有多种类型。例如，平均池化通过求平均值将多个值变成一个值。但是最大池化是最常见的池化类型。 最大池化： 一种池化过程，通过获取多个值中的最大值，将多个值变成一个值。 步长： 在图像上滑动核（滤波器）的间隔像素数量。 下采样： 降低图像大小的操作 扩展阅读：卷积神经网络综合指南 cha5 CNN深度学习Sebastian访谈过拟合是由偏差方差权值(bias-variance trade-off)导致的,相对于数据来说，参数越多，越有可能选择完全随机的解，而不是一个好的解。有两种方法可以解决过拟合问题，第一种方法是拆分数据集，如90%的数据作为训练集，10%的数据作为测试集，然后执行交叉验证(cross validation)，即使训练时没用到测试集检查模型性能，如果损失上升，则停止训练。第二种方法是约束网络。例如可以使权重加上偏差，假设使所有权重尽可能接近零，对这些权重的约束越强，越不可能过拟合。此外还可以设置测试集，训练集和验证集，这里还有一个问题，如果在测试集上测试了很多次，最终结果将过拟合测试集。 猫狗分类CNN网络不仅可以处理灰度图像，还可以处理彩色图像。 在这里将采用CNN结构训练一个可以识别猫狗的模型，所采用的数据集是微软Asirra猫狗数据集。数据集中的图片有两种标签：0代表cat, 1代表dog。该数据集中的图片尺寸各不相同，因但神经网路要求的输入尺寸是固定的，此需要进行预处理。tf.keras.layers.Flatten(input_shape=(28, 28, 1))函数在图像尺寸大小不同时，扁平化生成的以为数组的大小也不同，因此需要先将尺寸统一，再进行扁平化操作。彩色图像处理计算机会将彩色图像解析为三维数组，如下图所示：对RGB图像执行卷积运算即分别对R, G, B, 三个通道进行卷积操作，在计算出每个通道的结果后将其相加，再加上一个偏差值1，放入卷积输出中去。在实际使用CNN的时候，通常会采用多个三维过滤器，最后得出多个卷积输出结果。卷积输出的深度由卷积核的数量来决定。注意，在训练CNN时，我们将更新三维核中的值从而最小化损失函数。 最大池化在三维卷积输出的结果上执行最大池化运算的方法和灰度图像的运算方式相同。 colab键盘快捷键 ⌘/Ctrl+m,b：在当前选择的单元格下方创建一个空白代码单元格 ⌘/Ctrl+m,i：中断单元格的运行 ⌘/Ctrl+m,h：显示所有键盘快捷键列表 ⌘/Shift+Enter：执行当前单元格并自动新建下一个的单元格 要查看关于任何 TensorFlow API 方法的文档，请将光标放置在其左括号的正后方，然后按 Tab 键： Softmax 与 S 型函数在上个 Colab 中，我们使用了以下 CNN 结构： 1234567891011121314151617model = tf.keras.models.Sequential([ tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)), tf.keras.layers.MaxPooling2D(2, 2), tf.keras.layers.Conv2D(64, (3,3), activation='relu'), tf.keras.layers.MaxPooling2D(2,2), tf.keras.layers.Conv2D(128, (3,3), activation='relu'), tf.keras.layers.MaxPooling2D(2,2), tf.keras.layers.Conv2D(128, (3,3), activation='relu'), tf.keras.layers.MaxPooling2D(2,2), tf.keras.layers.Flatten(), tf.keras.layers.Dense(512, activation='relu'), tf.keras.layers.Dense(2, activation='softmax')]) 注意，最后一个层级（分类器）由一个 Dense 层（具有 2 个输出单元）和一个 softmax 激活函数组成，如下所示： tf.keras.layers.Dense(2, activation='softmax')在处理二元分类问题时，另一个常见方法是：分类器由一个 Dense 层（具有 1 个输出单元）和一个 sigmoid 激活函数组成，如下所示：tf.keras.layers.Dense(1, activation='sigmoid')这两种方法都适合二元分类问题，但是请注意，如果决定在分类器中使用 sigmoid 激活函数，需要将 model.compile() 方法中的 loss 参数从 ‘sparse_categorical_crossentropy’ 更改为’binary_crossentropy’，如下所示： 123model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) General machine learning workflow Examine and understand data Build an input pipeline Build our model Train our model Test our model Improve our model/Repeat the process","link":"/2020/02/23/Major/01.Tensorflow_Udacity/"},{"title":"Apollo学习","text":"Cha1: 自动驾驶概述自动驾驶的等级共有六个等级： L0： 基本等级，驾驶者是唯一决策者 L1：Driver Assistance, 车辆为驾驶员提供转向或加速支持，如cruise control L2: Partical Automation, 车辆负责部分驾驶功能，如Automatic Cruise control, Automatic Lane Keeping, 但驾驶员始终保持对系统的控制 L3: Conditional Automation, 车辆自主驾驶，但驾驶员必须准备在必要时间随时接管。 L4: No Human Interference,(Without Steering Wheel, Throttle or Brake but restricted in Geofence) 在该等级中驾驶的所有功能由车辆接管，并且并不期望驾驶员的介入。该等级的车辆可能根本没有方向盘和任何驾驶员控制装置, 但车辆的行驶会被限制在某些区域(地理围栏)，在地理围栏外车辆不能自主操作，或者根本无法操作 L5: Full Automation, 车辆可在任何可驾驶区域自主运行，并且该等级下车辆的自主驾驶水平大于或等于人类驾驶员的水平 Cha2: 高精度地图(HD map)简介：高精度地图包含大量的辅助信息，如道路网的精确三维表征(交叉路口布局，路标位置)，语义信息(信号灯，速度限制, 车道)等，高精度地图的精度可达到厘米级。高精度地图可用于定位，感知和规划等过程中。定位：高精度地图可以同于定位，车辆通过传感器感知的周围环境进行自定位，即根据所感知的环境信息找到自身在地图上所处位置。其流程为首先通过传感器采集数据(图像，三维点云等)，然后对数据进行预处理(消除不准确和低质量数据)，坐标转换(统一坐标系)，数据融合, 最后根据数据融合的数据和地狱进行匹配。感知：高精度地图和帮助无人驾驶车进行感知，用于克服传感器硬件，天气，亮度等条件对传感器感知能力的限制，除此之外高精地图可以用来缩小传感器检测范围，即为传感器提供ROI，其优点是可以提高检测精度和速度，同时也节约了计算能力。规划：高精度地图可以帮助车辆寻找合适的行车空间，用于路线规划；同时也可以告知车辆其他车辆可能出现的位置。在具有速度限制，障碍物的区域，高精度地图也可以为车辆的减速，变道等操作提供依据。 Apollo高精度地图Apollo的高精度地图采用OpenDRIVE标准，该标准格式可以像API一样方便调用，Apollo对该制图标准进行了改进，即Apollo OpenDRIVE.两种标准比较见下图。Apollo高精度地图的准确性要求比较高，因此需要调查车队对地图进行不断的更新，其构建过程如下图。除了高精度地图以外，Apollo还提供了俯瞰图和3D点云地图。 Cha3: 定位定位是让无人车确定自身位置的方法，常用的定位的方法有：GNSS RTK, 惯性导航，Lidar定位和视觉定位。定位所需要的输入有：GPS, IMU, LiDAR等。GNSS RTK：GNSS RTK定位的基础是三角测量，如下图所示，在平面上确定一个点的位置需要三个地标，在空间中则需要一个额外的地标来确定海拔。因此GPS需要至少4颗卫星才能进行定位。GPS是全球定位系统，是美国开发的定位系统名称。但该类系统的通用名称叫做全球导航卫星系统(GNSS)。GPS系统有三部分组成： 卫星：大约30颗，距地约两万公里 控制站：监控和控制卫星，验证GPS精度 GPS接收器: 不直接检测距离，而是检测信号飞行时间，计算方法如下下图。为保证精度，每颗卫星都有原子钟以保证时间的准确性GPS定位进一步减小误差的方法是实时运动定位(RTK), 通过卫星和基站的误差进行修正，通过误差可以将误差限制在10cm内。因此GPS定位系统的精度可以信赖，但收遮挡和区域的影响，并且更新频率很低(10Hz)。 惯性导航：基本原理是初中物理(v, a, t)，加速度采用三轴加速度计进行测量，并且借助陀螺仪的(3D Gyro)将加速度从Ego坐标系转换到全局坐标系。加速度计+陀螺仪=IMU，IMU工作频率很高，实时性强，但误差会随着时间而积累。LiDAR定位：LiDAR定位的方法是通过点云匹配，滤波等算法实现的。点云匹配算法(迭代最近点/ICP)的思想是：假设需要对两次点云扫描的数据进行匹配，首先建立两次扫描的匹配点对，然后将每对点之间的距离误差相加来计算平均距离误差，接下来的目标是通过点云的平移和旋转来最小化平均距离误差，从而可以找到传感器扫描和地图之间的匹配，最终将传感器扫描到的车辆位置转换为全球地图上的精确位置。滤波算法通过过滤冗余信息来在地图上找到最可能的车辆位置。Apollo采用直方图滤波算法(误差平方和算法/SSD)，该方法首先将传感器扫描的点云滑过地图上的每个位置，在每个位置计算扫描的点与高精度地图对应点之间的误差或距离，然后对误差的平方求和，得到的结果越小，则扫描结果与地图的匹配越好。此外还有卡尔曼滤波算法，该算法根据过去的状态和新的传感器测量结果预测当前的状态，即使用了预测更新周期。LiDAR的优点在于稳健性(robust)，但其难点是构建高精度地图并使其保持最新(瞬态元素太多？)。 视觉定位：视觉定位的优点是：图像数据类型获取成本较低，并且摄像头传感器种类繁多，价格便宜; 但通过图像很难实现精准定位，因此经常与其他传感器数据相结合来准确定位车辆(如：3D map + Image)。比如采用粒子滤波来确定汽车检测到的树对应地图上的哪棵树(如下图)。同样可以使用粒子滤波的原理确定车辆在车道线上的位置。 Apollo定位Apollo使用基于GPS, IMU和Lidar的多传感器融合定位系统，利用不同传感器的特性和优势，提高了定位的稳定性和准确性。数据融合的框架是卡尔曼滤波。 Cha4: 感知在自动驾驶控制系统的架构当中，自动驾驶车辆的感知系统是车辆路径规划的主要依据之一。感知系统最主要采用的传感器是Camera和Lidar。Camera图像的形式为RGB或者灰度，可以提供颜色，形状和纹理等信息; Lidar图像提供环境的点云特征，其原理是Lidar中激光束的反射，所收集的信息形成点云，每个点代表反射回传感器的激光束。点云数据中包含距离，高度以及表面和纹理信息。最终，感知模块的输出有四周车辆的三维识别框; 所检测的车辆的速度，角速度，方向; 地面标识，车道线等。 这里要注意的是感知模块的输出不是传感器的原始信息。在感知层面上，自动驾驶车辆主要有四个核心任务： Detection: 检测，确定物体的具体位置 Classification: 分类，明确对象类别 Tracking: 跟踪，随着时间的推移观察移动物体 Segmentation: 分割，即语义分割，将图像的每个像素与语义类别相匹配 机器学习机器学习是一种方法论，采用模型来对传感器的数据进行处理，模型需要学习过程，根据其学习的方法可分为： supervised Learning: 需要有标注的数据进行训练 Unsupervised Learning: 采用无标注的数据进行训练 Semi-supervised Learning： 半监督，两者结合 Reinforcement Learning: 强化学习，允许模型采用不同的方法解决问题，并衡量哪一种方法更加成功。 反向传播算法反向传播算法的过程由前馈，误差测定，和反向传播三个部分组成。 卷积神经网络标准的神经网络在处理图像分类问题的时候，需要首先采用平滑化操作(Flatten)将二维的图像变成一维的向量，即将所有的图像展开为一维像素序列，但这种方法的问题是会丢失图像的空间信息。CNN通过卷积操作来维持输入像素之间的空间关系来解决这一个问题。 如下图的CNN结构，在每一层上CNN采用不同的卷积算子来提取不同的图像特征如边缘，部件，色彩等，最终通过学习过程来找出哪些特征是重要的。 目标检测与分类检测算法有两种流派： Two stage model: RCNN, fast FCNN, Faster RCNN One stage model: YOLO, SSD 跟踪在检测出目标后，需要对目标进行跟踪，Tracking的意义在于可以解决在视频流中物体的遮挡问题，并且可保留识别码。知乎：工程实践中，目标检测为何要加目标追踪？分割语义分割设计对图像的每个像素进行分类，在自动驾驶中用于寻找通行空间。算法上语义分割依赖于全卷积网络(FCN)。不同于CNN，FCN采用卷积层来替代传统CNN结果的平滑层(flat layers)。在FCN中，输入图像经过多次卷积后得到的输出图像将比输入图像小，为了进行像素分割操作，可网络的中间输出采用上采样处理，使得最终输出的大小与原始图像大小相匹配。如下图，网络的前半部分被称为编码器，后半部分为解码器 Apollo感知对于三维对象的检测，Apollo的感知系统采用ROI来重点关注相关对象，Apollo将ROI fliter应用于点云和图像数据，用来缩小搜索范围并加快感知。其检测网络的结构如下图，检测网络的输出用于构建对象的Bounding box。紧接着采用检测和跟踪结合的算法来在时间步中检测单个对象。Apollo采用高精度地图来确定前方是否有信号灯，采用YOLO来检测车道线和动态目标。在通过YOLO网络检测后，在线检测模块会并入来自其他传感器的数据对车道线预测进行调整，车道线最终被放入Virtual Lane的数据结构中。同时来自其他传感器的数据也会对YOLO网络所检测到的动态对象进行调整，以获得每个对象的类别，位置，速度和前进方向。车道预测结果和动态对象检测结果最终均被传递到规划和控制模块。 传感器数据比较 Radar和Lidar补充知识在汽车系统中雷达主要应用于自适应巡航控制、盲点警告、碰撞浸膏和碰撞预防等系统中。尽管雷达技术已经成熟，它仍在不断进步，作用不断提升。其他传感器测量速度的方法是计算两次读数之间的差距，而雷达则通过多普勒效应来直接测量速度。多普勒效应对传感器融合至关重要。因为它可以把速度作为独立的测量参数，从而提升了融合算法的收敛速度。雷达还可以生成环境的雷达地图，进而实现定位。因为雷达波在坚硬表面会回弹。因此，它可以直接测量对象距离，无需在视线范围内也可以。雷达可以看到其他车辆底部。并发现可能会被阻挡的建筑物和对象。在车上的所有传感器中，雷达是至不容易受雨雾影响的。而且视野宽阔，可达150度，距离可达200多米。与激光雷达和摄像头相比，雷达分辨率较低，尤其是在垂直方向，分辨率非常有限。分辨率低意味着来自静态物体的反射可能产生问题。例如，街道上检修孔盖或汽水罐，可能产生很高的雷达反射率，但他们并不大。我们将其称为雷达杂波。因此，当前的车载雷达通常会忽视静态物体。 激光雷达是激光探测与测量的简称，而雷达则谁无线电探测与测量的简称。雷达使用无线电波，而激光雷达则使用红激光束来确定传感器和附近对象的距离。目前的激光雷达大多使用 900 纳米光波长度的光源。但部分激光雷达使用的光波长度更长，在雨雾中性能更好。当前的激光雷达使用旋转座架发射激光，扫描周边环境。激光室脉冲式的，脉冲被对象反射，然后返回一个点云，来代表这些物体。激光雷达的空间分辨率远远高于雷达。因为激光束越聚焦，垂直方向的扫描层数量就越多，因此每层的激光雷达的密度也越高。目前，激光雷达还不能直接测量对象的速度，必须使用两次或多次扫描之间的位置差来确定。激光雷达受天气和传感器清洁程度影响也很大，因此需要保持清洁。它们块头也比其他传感器更大，因此也很难安装，除非你只想在车顶安装一个大的激光扫描器。 感知融合策略Apollo采用Lidar和Radar来检测障碍物，用于融合输出的主要算法为卡尔曼滤波。 Cha6: 规划轨迹规划的目标是生成免碰撞和舒适的可执行的轨迹，该轨迹有一系列的点组成，每个点都有一个关联速度，以及一个时间戳(tamestap)用来表示何时到达该点。路线规划使用了三个输入：地图，当前在地图上的位置，目的地。在搜索可行路径之前，采用了基于图形搜索方法。首先将地图重新格式化为图形(graph)。graph由节点(node)和边缘(edge)组成。节点代表路段，边缘代表路段之间的连接。轨迹规划不仅需要再地图上规划路线，还需要根据环境以及周围的车辆行人等进行低等级高精度的轨迹生成。所生成的轨迹具有三个维度，空间上的两个维度和一个时间维度。现实世界的规划问题具有多种约束，如考虑车辆道路条件的限制，法律法规，乘客的舒适感，速度限制，在轨迹的终点车辆是否和道路中心线平行对齐等。在具体实现方法采用优化理论，通过最小化损失函数来找到最适合的路径。在路径规划中，笛卡尔坐标系并不适合解决这种问题，Frenet 坐标系描述了汽车相对于道路的位置，在 Frenet 框架中，s 代表沿道路的距离称为纵坐标，d表示与纵向线的位移称为横坐标。路径-速度解耦规划(EM规划)路径-速度解耦规划包括两步: 路径规划和速度规划。在路径规划中，首先生成候选曲线，使用成本函数对候选路径进行评估，需考虑的因素包括: 平滑度、安全性、与车道中心的偏离程度等。速度规划需要的是一系列与路径相关联的速度序列。路径规划： 具体实施步骤上，首先将路段分割成单元格，对这些单元格中的点进行随机采样。通过从每个单元格中取一个点并将点连接，创建了候选路径，通过重复此过程可以构建多个候选路径。使用成本函数对这些路径进行评估并选择成本最低的路径，成本函数可能考虑以下因素：与车道中心的偏离、与障碍物的距离、速度和曲率的变化、对车辆的压力等因素。 速度规划： 速度规划即需要选择与路径相关联的速度曲线。通过ST图可以帮助设计和选择速度曲线。在这里需要将ST图离散为多个单元格，每个单元格内速度保持不变，通过该方法可简化速度曲线的构建并维持曲线的近似度。在 ST 图中可以将障碍物可表达为在特定时间段内阻挡道路的矩形。为避免碰撞，速度曲线不得与此矩形相交，使用优化引擎为该图选择最佳的速度曲线。优化算法通过复杂的数学运算来搜索，受到各种限制的低成本解决方案，这些限制可能包括：法律，速度、与障碍物的距离、汽车的性能等。 优化： 为了将离散解决方案转换为平滑轨迹，可使用“二次规划”技术。二次规划将平滑的非线性曲线与这些分段式线性段拟合。 Lattice规划Lattice规划，通过使用Frenet坐标可以将环境投射到纵轴和横轴上，目标是生成三维轨迹: 纵向维度、横向维度、时间维度。在具体处理上，可以将三维问题分解成两个单独的二维问题，即轨迹的纵向分量(ST轨迹)和横向分量(SL轨迹)。 ST轨迹的终止状态有三种： ** 巡航:** 巡航意味着车辆将在完成规划步骤后定速行驶，实际上在对图上的点进行采样，在图中横轴代表时间，纵轴代表速度。对于该图上的点，这意味着汽车将进入巡航状态，在时间 t 以 s 点的速度巡航，对于这种模式，所有最终状态的加速度均为零。 ** 跟随: ** 在这种情况下要对位置和时间状态进行采样，并尝试在时间t出现在某辆车后面，在跟随车辆时，需要与前方的车保持安全距离，这时速度和加速度将取决于要跟随的车辆，这意味着在这种模式下，速度和加速度都会进行修正。 ** 停止: ** 对于这种模式只需对汽车何时何地停止进行抽样，这里速度和加速度会被修正为0。 SL的终止状态：无论车辆进入怎样的终止状态，车辆都应该稳定地与车道中心线对齐。因此只需要在小区域内，对横向终止位置进行采样。具体来说采样的是道路上相邻车道中心线周围的位置，为了确保稳定性。汽车驶向的终止状态应该与车道中心一致，在路径规划中，车辆的最终状态应与车道对齐并直线行驶而结束，即车的朝向和位置的一阶和二阶导数都应该为零。这意味着车辆既不是横向移动的那是一阶导数，也不是横向加速那是二阶导数，这意味着车辆正沿着车道直行。 拟合多项式与评估如何连接初始状态和结束状态? Cha7 控制控制是驱使车辆前行的策略，对于汽车而言，最基本的控制输入为转向、加速、制动。控制器使用一系列路径点来接收轨迹，其目标是使用可行的控制输入，最大限度地降低与目标轨迹的偏差，最大限度地提高乘客的舒适度。可用于实现这些目标的三种控制策略比例积分微分控制(PID)、线性二次调节器(LQR)、模型预测控(MPC)。 PIDPID是一种线性控制算法，不适用于复杂系统，对无人驾驶车，需要应用不同的 PID 控制器来控制转向和加速，这意味着很难将横向和纵向控制结合起来。并且PID控制器依赖于实时误差测量，意味着受到测量延迟的限制。 LQRLQR是基于模型的控制器，使用车辆状态来最小化误差。Apollo 使用 LQR 进行横向控制，横向控制包含四个参数：横向误差、横向误差的变化率、朝向误差、朝向的变化率。用集合x表示 ，x可捕获车辆的状态。车辆有三个控制输入：转向、加速、制动，用集合u表示。在线性控制时，其控制器模型如下图。x_dot是导数或x向量的变化率。该等式是线性的，因为用△x来改变x时，并用△u来改变u，x点的变化也会让这个等式成立。控制的目标是为了让误差最小化同时尽可能少地使用控制输入，由于使用这些会有成本。为了尽量减少这些因素，可以保持误差的运行总和和控制输入的运行总和。当汽车往右偏转得特别厉害之际，添加到误差总和中，当控制输入将汽车往左侧转时，从控制输入总和中减去一点。然而这种方法会导致问题，因为右侧的正误差只需将左侧的负误差消除即可，对控制输入​​来说也是如此。相反可以让x乘以u，这样负值也会产生正平方，称这些为二次项。为这些项分配权重并将它们加在一起，最优的u应该加倍减总和，在数学中将这个值称为成本函数。经常写出加权二次项的总和，这里Q和R代表x和u的权重集合, X和Ut是转置矩阵，意味着它们几乎与x和u相同，只是重新排列 以便矩阵乘法。x乘以Xt,u乘以Ut，实质上是将每个矩阵乘以它自己。最小化成本函数是一个复杂的过程，但通常可以依靠数值计算器找到解决方案。在Apollo中，LQR控制器被表达为：u=-Kx。求解的目标就是找到一个最优的K。 MPC模型预测是一种复杂的控制器，最初用于工业领域。也是一种基于模型的控制器。MPC是一种多变量的控制算法，采用程序的内在动态模型，过去的控制信号，针对滚动预测域的最佳化成本函数J来计算最优化的控制信号。它由预测模型，反馈校正，滚动优化和参考轨迹四个部分组成。对于其预测能力，预测越深入，控制器就越精确，不过需要的时间也越长。所以需要在准确度与快速获取结果之间做出取舍，获取结果的速度越快，越能快速地将控制输入应用到实际车辆中。MPC优劣对比：MPC考虑了车辆模型，因此比PID控制更精确，也适用于不同的成本函数。另一方面与PID控制相比，模型预测控制相对更复杂、更缓慢、更难以实现。在实践中无人驾驶车的控制可扩展性的重要程度，通常意味着值得为MPC投入实现成本，所以MPC成为了一个非常重要的无人驾驶车控制器。","link":"/2020/02/25/Major/02.Apollo_Introduction/"},{"title":"学习资源整理：自动驾驶，深度学习，目标检测","text":"自动驾驶公开课 百度Apollo自动驾驶课： 无人驾驶第一课：从 Apollo 起步 多伦多大学自动驾驶课：自动驾驶汽车 专项课程 优达学城自动驾驶纳米学位：无人驾驶入门 MIT自动驾驶公开课：MIT 6.S094: Deep Learning for Self-Driving Cars 图像目标检测Review, survey Object Detection with Deep Learning: A Review Deep Learning for Generic Object Detection: A Survey Object Detection in 20 Years: A Survey 博客，论文解析 RCNN,SPPNet,Fast RCNN,FasterRCNN论文详解 YOLO系列论文详解 Github Project: deep_learning_object_detection 点云目标检测博客，论文解析 激光雷达目标检测上 激光雷达目标检测下 激光雷达目标检测论文集 激光雷达目标检测好文 预测： https://www.jiqizhixin.com/articles/2019-02-13-23 https://www.jiqizhixin.com/articles/2019-05-14-4 其他 colab项目集合： https://github.com/firmai/awesome-google-colab Awesome Machine Learning Jupyter Notebooks for Colab项目：https://github.com/toxtli/awesome-machine-learning-jupyter-notebooks-for-colab 谷歌自动驾驶车项目2017：https://www.youtube.com/watch?v=O2bXF7XJ5P0&amp;feature=youtu.be&amp;t=2343","link":"/2020/03/08/Major/03.Resource_for_self_driving/"},{"title":"nvidia常用命令","text":"Nvidia相关命令 nvidia-smi: 调用nvidia系统管理界面 nvidia-smi -L： 列出所有GPU nvidia-smi -i 0： 查询特定卡的信息，0.1.2.为GPU编号 nvidia-smi pmon： 监控线程 nvidia-smi dmon： 监控设备 nvidia-smi -q： 查询所有信息 nvidia-smi -l 3：持续监控gpu状态，每三秒刷新一次状态 nvidia-smi 信息解读 Fan：风扇转速，从0到100%之间变动，这个速度是计算机期望的风扇转速，实际情况下如果风扇堵转，可能打不到显示的转速。有的设备不会返回转速，因为它不依赖风扇冷却而是通过其他外设保持低温 Temp：温度，单位摄氏度。 Perf：性能状态，从P0到P12，P0表示最大性能，P12表示状态最小性能。 Pwr：能耗，上方的Persistence-M：是持续模式的状态，持续模式虽然耗能大，但是在新的GPU应用启动时，花费的时间更少。 Bus-Id：GPU总线，domain:bus:device.function Disp.A：Display Active，表示GPU的显示是否初始化。 Memory Usage：显存使用率。 Compute M：是计算模式。","link":"/2020/01/01/Major/05.NVIDIA/"},{"title":"基于鸟瞰图的点云目标检测：PIXOR","text":"摘要该文章解决了在自动驾驶环境下从点云实时检测三维物体的问题。因为检测是安全的必要组成部分，所以计算速度至关重要。然而，由于点云的高维性，现有方法的计算成本很高。本文通过从鸟瞰图( BEV )中表示场景来更有效地利用3D数据，并提出PIXOR，这是一种无需处理的、单级的检测器，输出从像素级别的神经网络定向解码估计3D对象。模型的输入形式、网络架构和优化器是为了平衡高精度和实时效率而特别设计的。作者在两个数据集上验证PIXOR的效果——KITTI BEV对象检测基准数据集和大规模3D车辆检测基准数据集。在这两个数据集上，我们表明检测器在平均精度(AP)方面明显优于其他最先进的方法，同时仍以大于28 FPS的速度运行。 简介在过去的几年里，我们已经看到了大量利用卷积神经网络来产生精确的2D物体检测的方法，通常是从单个图像为主的模型（如Faster R-CNN和YOLO）。然而，在机器应用中，例如自主驾驶，我们对检测3D空间中的物体更为感兴趣。为了规划安全路线，这是运动规划的基础。 3D对象检测的最新方法利用不同的数据源。基于相机的方法利用单目或立体图像（双目摄像机RGB+HHA）。然而，从2D图像中精确的3D估计是困难的，特别是在长距离范围内。随着廉价RGB-D传感器如微软Kinect、英特尔RealSense和苹果PrimeSense的普及，出现了几种利用深度信息并将其与RGB图像融合的方法。与单目方法相比，它们已经显示出显著的性能提升。在自动驾驶的情况下，像LIDAR(光探测和测距)这样的高端传感器更常见，因为为了安全需要更高的精确度。处理LIDAR数据的主要困难是传感器以点云的形式产生非结构化数据，每360度扫描通常包含大约10^5个3D点。这给现代探测器带来了巨大的计算挑战。 在三维物体检测的背景下，已经探索了不同形式的点云表示。主要的想法是形成一个结构化的表示，其中可以应用标准卷积运算。现有表示主要分为两种类型: 3D体素网格和2D投影。3D体素网格将点云转换成规则间隔的3D网格，其中每个体素单元可以包含标量值(例如，占用率)或矢量数据(例如，根据该体素单元内的点计算的统计数据)。3D卷积通常用于从体素网格中提取高阶表示。然而，由于点云本质上是稀疏的，因此体素网格非常稀疏，很大一部分计算是冗余和不必要的，用这种表示的典型系统仅运行在1-2 FPS。 另一种方法是将点云投影到平面上，然后将平面离散为基于2D图像的表示，在此应用2D卷积。在离散化期间，手工制作的特征(或统计)被当做2D图像的像素值计算。常用的投影是范围视图(即360度全景视图)和鸟瞰图(即俯视图)。这些基于2D投影的表示更加紧凑，但是它们在投影和离散化过程中会带来信息损失。例如，范围视图投影将具有失真的对象大小和形状。为了减轻信息损失，MV3D建议将2D投影与摄像机图像融合，以带来额外信息。然而，融合模型相对于输入模态的数量具有近似线性的计算成本，使得实时应用不可行。 在这篇论文中，作者提出了一种精确的实时三维物体检测器，称之为PIXOR (ORiented 3D object detection from PIXel-wise neural network predictions)，它是在点云上运行的网络。PIXOR是一种单级、无二次处理（例如YOLO和SSD）的密集物体检测器，它以高效的方式利用2D鸟瞰图(BEV)表示。我们选择BEV表示，因为它在计算上比3D体素网格更友好，并且还保留了度量空间，这使得我们的模型能够探索关于对象类别大小和形状的先验。我们的探测器在鸟瞰图中输出真实世界尺寸的精确定向边界框。请注意，这些是三维估计，但必须假设物体在地面上，因为车辆不会飞，这也是自动驾驶场景中的合理假设。 作者在两个数据集上展示了其方法的有效性。具体来说，PIXOR在所有先前的方法中，实现了KITTI鸟瞰对象检测基准的最高平均精度(AP)，同时也是其中运行最快的(超过28FPS)。作者还在KITTI上提供了深入的消融研究，以调查每个模块贡献了多少性能增益，并通过将其应用于大规模TOR4D数据集来证明PIXOR的可扩展性和泛化能力。 模型结构在本文中，作者提出了一种高效的三维物体检测器，它能够在给定LIDAR点云的情况下产生非常精确的边界框。这里的边界框估计不仅包含3D空间中的位置，还包含航向角，因为准确预测这对于自主驾驶非常重要。我们利用LIDAR点云的2D表示，因为它比3D体素网格表示更紧凑，因此可以进行实时推断。图1显示了提议的3D物体检测器的概述。 Input Representation由于要用标准卷积神经网络执行卷积操作，因此我们必须假设输入位于网格上。然而，3D点云是非结构化的，因此标准卷积不能直接应用在其上。一种选择是使用体素化来形成3D体素网格，其中每个体素单元包含位于该体素内的点的某些统计数据。为了从三维体素网格中提取特征表示，经常使用三维卷积。但这3DCNN的计算代价非常昂贵，并且因为LIDAR点云非常稀疏，以至于大多数体素单元都是空的。 相反，我们可以单独从鸟瞰图(BEV)中描绘场景。通过将维度从三维降低到二维，而不会丢失点云中的信息。因为我们可以将高度信息保留到颜色通道中。不仅如此，我们还有效地得到了更紧凑的表示方式，因为可以对BEV表示应用2D卷积。在自动驾驶的情况下，因为感兴趣的对象是在同一场地上，这种尺寸减小是合理的。除了计算效率之外，BEV表示还有其他优势。与前视图表示相比，由于对象不相互重叠，因此它简化了对象检测的问题。它还保留了度量空间，因此网络可以利用物体物理尺寸的先验信息。 体素化LIDAR表示的常用特征是占有率occupancy、强度intensity(也称反射率)、密度和高度特征。在PIXOR中，作者只使用占用率和强度作为特征。作者定义感兴趣的场景的三维物理尺寸L × W × H。然后，计算分辨率为dL × dW × dH的占用率特征，再计算分辨率为dL×dW×H的强度特征。注意，作者在占用率特征中增加了两个额外的通道，以覆盖范围外的点。最终表示的形状为L/dL × W/dW × (H/dH + 3) Network ArchitecturePIXOR使用一个全卷积结构，设计用于密集定向的3D物体检测，并且没有使用类似于R-CNN的分支处理，相反网络在单个阶段输出像素预测，每个预测对应于3D对象估计。因此，根据定义，PIXOR的召回率是100%。多亏了完全非传统的架构，这样密集的预测可以非常有效地计算出来。就网络预测中3D对象的编码而言，作者构建了直接编码的模型，而不求助于预定义的object anchors。所有这些设计使得PIXOR变得非常简单，并且由于网络架构中的零超参数而得到很好的推广。具体来说，不需要设计object anchors，也不需要调整从第一阶段传递到第二阶段的关注区域以及相应的非最大抑制阈值。 整个体系结构可以分为两个子网络:主干网络Backbone network和头网络Header network。主干网络用于提取卷积特征并映射成输入的一般表示。它具有很高的表示能力来学习一个健壮的特征表示。头网络用于进行特定于任务的预测，在该例子中，它有一个具有多任务输出的单分支结构：对象分类和定位。 Backbone Network卷积神经网络通常由卷积层和池化层组成。卷积图层用于提取输入要素的过度完整表示，而池化图层用于对要素地图大小进行下采样，以节省计算并帮助创建更健壮的表示。许多基于图像的物体检测器中的主干网络通常具有16倍下采样因子，并且通常被设计成具有更少的高分辨率层和更多的低分辨率层。它对图像很有效，因为对象通常像素尺寸很大。然而，在本文的情况下，这将导致一个问题，因为对象可能非常小。当离散分辨率为0.1m时，典型车辆的尺寸为18×40像素。16倍下采样后，它仅覆盖约3像素。 一个直接的解决方案是使用更少的池化层。然而，这将减小最终特征图中每个像素的感受野的大小，这限制了表现能力。另一个解决方案是使用膨胀卷积，但这将导致在高级特征地图中出现棋盘状伪像（checkerboard artifacts）。作者的解决方案很简单，使用16倍下采样因子，但是做了两个修改。首先，在较低的级别添加更多的通道数量较少的层，以提取更多的细节信息。其次，我们采用了类似FPN的自上而下的分支，将高分辨率特征图和低分辨率特征图相结合，以便对最终的特征表示进行上采样。 从Figure2可以看出主干网络中总共有五个层块。第一块由两个卷积层组成，通道为32，步长为1。第二至第五块由残差层组成（层数分别等于3、6、6、3）。每个残差块的第一卷积具有步长2，以便对特征图进行下采样。总的来说，下采样系数是16。为了对要素图进行上采样，其添加了一条自上而下的路径，每次对要素图进行2倍的上采样。然后，通过像素求和，这与相应分辨率的自下而上的特征图相结合。使用两个上采样层，这导致最终的特征图具有四倍下采样的大小。 Header Network头网络是一个多任务网络——对象识别和方向定位。它被设计成小巧高效。分类分支输出1个通道特征图，跟sigmoid函数激活；回归分支输出线性的6通道特征图。在这两个分支之间分享权重的层数上存在权衡。一方面，我们希望更有效地利用重量。另一方面，由于它们是不同的子任务，我们希望它们更加独立和专业化。在下一章中，我们对这种权衡进行了一项调查性实验，发现两项任务的权重分配会带来稍微更好的性能。 我们将每个对象参数化为定向的bounding box b {θ，xc，yc，w，l}=，每个元素对应于在[−π，π][−π，π]范围内的航向角、对象的中心位置(xc，yc)和对象的大小(w，l)。与基于长方体的三维物体检测相比，我们省略了沿Z轴的位置和尺寸，因为在像自主驾驶这样的应用中，感兴趣的物体被限制在同一个接地面上，因此我们只关心如何在那个平面上定位它。给定这样的参数化，回归分支的表示是{cos(θ)，sin(θ)，dx，dy，w，l}，对于位置(px，py)(如图3中的红点所示)。注意，航向角被分解为两个相关值，以加强角度范围约束。 在推理过程中，我们将θ解码为atan2(sin(θ)，cos(θ))。(dx，dy)对应于从像素位置到物体中心的位置偏移。(w，l)对应于对象大小。值得注意的是，对象位置和大小的值在现实世界的度量空间中。最后的学习目标是{cos(θ)，sin(θ)，dx，dy，log(w)，log(l)}，它在训练集之前被标准化为具有零均值和单位方差。 Learning and Inference与传统的多任务网络类似，其Loss的计算方式如下所示，其中focal_loss为分类的损失，smooth为回归的损失。","link":"/2020/04/08/Major/04.Pixor/"},{"title":"点云数据生成鸟瞰图表示","text":"点云数据点云数据是点的集合，由激光雷达采集获得，点云数据应表示为具有N行，具有4列的numpy数组。每行对应一个点，该点在空间（x，y，z）使用3个值表示。 第四个值是附加值，通常为反射率(强度)。 鸟瞰图表示鸟瞰图是俯视视角下点云的一种图形表示。 在自动驾驶中，该表示方法的合理性基于一个前提: 所有的车辆都在地面行驶，因此可以直接将数据展平在x, y平面中。 点云数据转换为鸟瞰图的步骤为： 设置感兴趣的区域(Region of Interest), 区域大小为L * W * H. 设置分辨率，将Region of Interest栅格化，并将点云的位置映射到鸟瞰图上的像素位置，计算occupancy map 按照高度将鸟瞰图划分为不同的通道，以保存点云数据中的高度信息。 鸟瞰图生成代码import numpy as np # ============================================================================== # SCALE_TO_255 # ============================================================================== def scale_to_255(a, min, max, dtype=np.uint8): &quot;&quot;&quot; Scales an array of values from specified min, max range to 0-255 Optionally specify the data type of the output (default is uint8) &quot;&quot;&quot; return (((a - min) / float(max - min)) * 255).astype(dtype) # ============================================================================== # POINT_CLOUD_2_BIRDSEYE # ============================================================================== def point_cloud_2_birdseye(points, res=0.1, side_range=(-10., 10.), # left-most to right-most fwd_range = (-10., 10.), # back-most to forward-most height_range=(-2., 2.), # bottom-most to upper-most ): &quot;&quot;&quot; Creates an 2D birds eye view representation of the point cloud data. Args: points: (numpy array) N rows of points data Each point should be specified by at least 3 elements x,y,z res: (float) Desired resolution in metres to use. Each output pixel will represent an square region res x res in size. side_range: (tuple of two floats) (-left, right) in metres left and right limits of rectangle to look at. fwd_range: (tuple of two floats) (-behind, front) in metres back and front limits of rectangle to look at. height_range: (tuple of two floats) (min, max) heights (in metres) relative to the origin. All height values will be clipped to this min and max value, such that anything below min will be truncated to min, and the same for values above max. Returns: 2D numpy array representing an image of the birds eye view. &quot;&quot;&quot; # EXTRACT THE POINTS FOR EACH AXIS x_points = points[:, 0] y_points = points[:, 1] z_points = points[:, 2] # FILTER - To return only indices of points within desired cube # Three filters for: Front-to-back, side-to-side, and height ranges # Note left side is positive y axis in LIDAR coordinates f_filt = np.logical_and((x_points &gt; fwd_range[0]), (x_points &lt; fwd_range[1])) s_filt = np.logical_and((y_points &gt; -side_range[1]), (y_points &lt; -side_range[0])) filter = np.logical_and(f_filt, s_filt) indices = np.argwhere(filter).flatten() # KEEPERS x_points = x_points[indices] y_points = y_points[indices] z_points = z_points[indices] # CONVERT TO PIXEL POSITION VALUES - Based on resolution x_img = (-y_points / res).astype(np.int32) # x axis is -y in LIDAR y_img = (-x_points / res).astype(np.int32) # y axis is -x in LIDAR # SHIFT PIXELS TO HAVE MINIMUM BE (0,0) # floor &amp; ceil used to prevent anything being rounded to below 0 after shift x_img -= int(np.floor(side_range[0] / res)) y_img += int(np.ceil(fwd_range[1] / res)) # CLIP HEIGHT VALUES - to between min and max heights pixel_values = np.clip(a=z_points, a_min=height_range[0], a_max=height_range[1]) # RESCALE THE HEIGHT VALUES - to be between the range 0-255 pixel_values = scale_to_255(pixel_values, min=height_range[0], max=height_range[1]) # INITIALIZE EMPTY ARRAY - of the dimensions we want x_max = 1 + int((side_range[1] - side_range[0]) / res) y_max = 1 + int((fwd_range[1] - fwd_range[0]) / res) im = np.zeros([y_max, x_max], dtype=np.uint8) # FILL PIXEL VALUES IN IMAGE ARRAY im[y_img, x_img] = pixel_values return im pointcloud = np.fromfile(str(&quot;000000.bin&quot;), dtype=np.float32, count=-1).reshape([-1, 4]) bev = point_cloud_2_birdseye(pointcloud) 生成的鸟瞰图：","link":"/2020/03/15/Major/06.point_cloud_bev/"},{"title":"KITTI数据集标签","text":"KITTI detection数据集标签数据集标签实例： 标签含义： Values Name Description 1 type Describes the type of object: ‘Car’, ‘Van’, ‘Truck’,’Pedestrian’, ‘Person_sitting’, ‘Cyclist’, ‘Tram’,’Misc’ or ‘DontCare’ 1 truncated Float from 0 (non-truncated) to 1 (truncated), where truncated refers to the object leaving image boundaries 1 occluded Integer (0,1,2,3) indicating occlusion state: 0 = fully visible, 1 = partly occluded, 2 = largely occluded, 3 = unknown 1 alpha Observation angle of object, ranging [-pi..pi] 4 bbox 2D bounding box of object in the image (0-based index): contains left, top, right, bottom pixel coordinates 3 dimensions 3D object dimensions: height, width, length (in meters) 3 location 3D object location x,y,z in camera coordinates (in meters) 1 rotation_y Rotation ry around Y-axis in camera coordinates [-pi..pi] 1 score Only for results: Float, indicating confidence in detection, needed for p/r curves, higher is better. 第1个字符串：代表物体类别 ‘Car’, ‘Van’, ‘Truck’,’Pedestrian’, ‘Person_sitting’, ‘Cyclist’,’Tram’, ‘Misc’ or ‘DontCare’ 注意，’DontCare’ 标签表示该区域没有被标注，比如由于目标物体距离激光雷达太远。为了防止在评估过程中（主要是计算precision），将本来是目标物体但是因为某些原因而没有标注的区域统计为假阳性(false positives)，评估脚本会自动忽略’DontCare’ 区域的预测结果。 第2个数：代表物体是否被截断 从0（非截断）到1（截断）浮动，其中truncated指离开图像边界的对象 第3个数：代表物体是否被遮挡 整数0，1，2，3表示被遮挡的程度 0：完全可见 1：小部分遮挡 2：大部分遮挡 3：完全遮挡（unknown） 第4个数：alpha，物体的观察角度，范围：-pi~pi 是在相机坐标系下，以相机原点为中心，相机原点到物体中心的连线为半径，将物体绕相机y轴旋转至相机z轴，此时物体方向与相机x轴的夹角 第5～8这4个数：物体的2维边界框 xmin，ymin，xmax，ymax 第9～11这3个数：3维物体的尺寸 高、宽、长（单位：米） 第12～14这3个数：3维物体的位置 x,y,z（在照相机坐标系下，单位：米） 第15个数：3维物体的空间方向：rotation_y 在照相机坐标系下，物体的全局方向角（物体前进方向与相机坐标系x轴的夹角），范围：-pi~pi 第16个数：检测的置信度","link":"/2020/03/03/Major/07.KITTI_datasets/"},{"title":"pytorch学习","text":"pytorch常用代码 在pytorch中使用tensorboard: https://www.pytorchtutorial.com/pytorch-builtin-tensorboard/ pytorch常用代码段合集： https://zhuanlan.zhihu.com/p/59205847 pytorch踩坑记录 ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm) 出现这个错误的情况是，在服务器上的docker中运行训练代码时，batch size设置得过大，shared memory不够（因为docker限制了shm）.解决方法是，将Dataloader的num_workers设置为0. 参考：https://zhuanlan.zhihu.com/p/59271905 AttributeError: module ‘scipy.misc’ has no attribute ‘toimage’ 解决方法：由于安装的scipy版本是1.4版本，该版本删除了toimage函数，最方便的解决办法降版本 $ pip uninstall scipy $ pip install scipy==1.2.0 ModuleNotFoundError: No module named ‘tkinter’ 在utils.py中添加以下代码： import matplotlib matplotlib.use(‘agg’) import matplotlib.pyplot as plt","link":"/2020/05/01/Major/08.learn_pytorch/"},{"title":"C语言基础-嵌入式面试","text":"1. C和C++区别： C语言：面向过程的语言，其核心关注于问题是如何被解决的，把实现一个软件功能的过程分为一个个过程。 例如汽车要去加油，其过程为：汽车启动-&gt;汽车行驶-&gt;汽车加油。在这里我们不关注物件本身(汽车这个对象)，默认定义执行该过程的主题是汽车。 C++语言： 面向对象的语言，在计算机科学中的对象既可以表示客观世界的问题空间(namespace)中的具体的某个事物，又可以表示软件系统解空间的基本元素，如变量、数据结构、函数等。例如汽车要去加油，汽车&lt;启动，开车，加油&gt;, 我们关注物件(对象)本身，只需要考虑什么时间干什么事。启动，开车，加油属于这个物件的基本属性。 C语言基础部分： 标识符： 一个标识符以字母或者下划线开始的后面可以跟多个字母、数字、下划线。C标识符中不允许出现标点字符，并且区分大小写。 关键字： C中的保留字，这些保留字不能作为常量名，变量名和其他标识符的名称。常用的的关键字包括:while, do, for, break, continue, default, goto, char, double, int, long, short, float, 关键字 说明 auto 声明自动变量 const 定义常量，如果一个变量可以被const修饰，那么它的值就不能被在改变 enum 声明枚举类型 extern 声明变量或函数是在其他文件或本文件其他位置定义 register 声明寄存器变量 sizeof 计算数据类型或变量长度(即所占的字节数) static 声明静态变量 typeof 给数据类型取别名 union 声明共用体类型 void 声明函数无返回值或者无参数，声明无类型指针 volatile 说明变量在程序执行中可以被隐含的改变 **数据类型： ** C语言有四种数据类型： **基本数据类型: **他们是算术类型，包括整数类型和浮点类型，注意char是属于整数类型的。 基本数据类型占用的空间(64位机器)：char-1字节，int-4字节， float-4字节，double-8字节。 枚举类型： 他们也是算术类型，被用来定义在程序中，只能赋予其一定的离散整数值的变量 void类型： 类型说明符 void表明没有可用的值 派生类型： 它们主要包括：指针，数组，结构，共用体，和函数类型 强制类型转换： (类型说明符)(表达式) 变量：变量是程序可操作的存储区名称。全局变量保存在内存的全局存储区中，占用静态的存储单元；局部变量保存在栈中，只有在所在函数被调用的时候才动态地为变量分配存储单元。 C语言经过编译后将内存分为一下几个区域： 栈(stack): 由编译器进行管理，自动分配和释放，存放函数调用过程的各种参数，局部变量，返回值以及函数的返回地址。操作方式类似于数据中的栈。 堆(heap): 用于程序动态申请分配和释放空间。C语言中的malloc和free，C++中的new和delete均是在堆中进行的。正常情况下，程序员申请的空间在使用结束后应该释放，若程序员没有释放空间，则在程序结束后由系统自动回收。注意：这里的对并不是数据结构中的堆。 全局(静态)存储区: 分为DATA和BSS段，DATA段(全局初始化区)存放初始化的全局变量和静态变量；BSS段(全局未初始化分区) 存放未初始化的全局变量和静态变量。程序运行结束时自动释放，其中在BSS段在程序执行之前会被系统自动清零，所以未初始化的全局变量和静态变量在程序执行之前已经为0. 文字常量区：存放常量字符串，程序结束由系统释放。 程序代码区：存放程序的二进制代码。 因此，C语言的全局变量和局部变量在内存之中是有区别的，C语言的全局变量包括外部变量和静态变量，均是保存在全局存储区中，占用永久性的存储单元；局部变量，即自动变量，保存在栈中，只有在所在的函数被调用时才有系统动态在栈中分配临时性的存储单元。 1234567891011121314151617181920212223242526272829#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int k1 = 1;int k2;static int k3 = 2;static int k4;int main( ){ staticint m1=2, m2; inti=1; char*p; charstr[10] = &quot;hello&quot;; char*q = &quot;hello&quot;; p= (char *)malloc( 100 ); free(p); printf(&quot;栈区-变量地址 i：%p\\n&quot;, &amp;i); printf(&quot; p：%p\\n&quot;, &amp;p); printf(&quot; str：%p\\n&quot;, str); printf(&quot; q：%p\\n&quot;, &amp;q); printf(&quot;堆区地址-动态申请：%p\\n&quot;, p); printf(&quot;全局外部有初值 k1：%p\\n&quot;, &amp;k1); printf(&quot; 外部无初值 k2：%p\\n&quot;, &amp;k2); printf(&quot;静态外部有初值 k3：%p\\n&quot;, &amp;k3); printf(&quot; 外静无初值 k4：%p\\n&quot;, &amp;k4); printf(&quot; 内静态有初值 m1：%p\\n&quot;, &amp;m1); printf(&quot; 内静态无初值 m2：%p\\n&quot;, &amp;m2); printf(&quot;文字常量地址 ：%p, %s\\n&quot;,q, q); printf(&quot;程序区地址 ：%p\\n&quot;,&amp;main); return0;} 常量常量是固定值，在程序的执行期间不会改变。它可以是任意基本的数据类型，整数常量，浮点常量，字符常量，枚举常量等。 定义常量： 定义常量有两种方法，使用#define或者使用const关键字，这两种方法从本质上是不同的。#define 是宏定义，它不能定义常量，但宏定义可以实现在字面意义上和其它定义常量相同的功能，本质的区别就在于 #define 不为宏名分配内存，而 const 也不为常量分配内存，怎么回事呢，其实 const 并不是去定义一个常量，而是去改变一个变量的存储类，把该变量所占的内存变为只读！ 示例 #define length 10 #define NEWLINE ‘\\n’ const int var=5; 整数常量：整数常量可以是十进制，八进制，十六进制的常量，前缀指定基数，0x/0X表示十六进制，0表示八进制，不带前缀默认代表十进制。整数常量也可以带一个后缀，U代表无符号整数, L代表长整数，大小写和顺序任意。 C++语言的三大特性 封装： C++语言支持数据封装，类是数据封装的工具，对象是数据封装的实现，在封装中，还提供一种对数据访问控制的机制，是的一些数据隐藏在封装体内，具有隐藏性。封装和外接的信息交换是通过操作接口进行的，这种访问的控制机制体现在类的共有成员(public)，私有成员(private)，和保护成员(protected)上。私有成员只有类内说明的一些函数才能访问；共有成员类外的函数也可以访问，保护成员只有该类的成员函数和派生类才能访问。 继承： C++语言允许单继承和多继承。一个类可以根据需要生成它的派生类，派生类还可以再生成派生类。派生类可以继承基类的成员同时也可以定义自己的成员。继承是实现数据抽象和共享的一种机制。该机制可以避免不能重复利用程序导致的资源浪费。 多态： 多态指的是对不同类发出的相同消息会有不同的实现。多态性也可以理解为，在一般类中定义的属性和服务被特殊类继承后，可以具有不同的数据类型或不同的实现。简单来说，多态性指的是发出同样的消息被不同的数据类型的对象接收后会导致不同的行为。C++支持多态性主要表现在：C++语言允许函数重载和运算符重载；C++语言通过定义虚函数来支持动态联编。多态特性的工作依赖虚函数的定义，在需要解决多态问题的重载成员函数前，加上virtual关键字，那么该成员函数就变成了虚函数，从上例代码运行的结果看，系统成功的分辨出了对象的真实类型，成功的调用了各自的重载成员函数。","link":"/2021/05/01/work/001.c_basic/"},{"title":"ISO26262标准","text":"ISO26262标准是什么随着汽车电气化程度的进一步提升，电子电气系统越来越集成和复杂，因此需要一些眼科的技术标准来规范汽车电子相关功能安全。 ISO26262标准是汽车的电气/电子相关的“功能安全”标准。该标准制定于2011年11月，2018年发布了第二版，并追加了半导体指南。 该标准是预先计算出汽车电控方面的故障风险，并把降低该风险的机制作为功能的一部分预先植入到系统当中，从而实现“功能安全”的标准化开发工艺。ISO26262标准的对象涵盖从车辆构思到系统，ECU(电子控制单元)，嵌入式软件，元器件开发及相关的生产、维护、报废等整个车辆的开发周期。 ISO26262功能安全定义本质安全和功能安全： 本质安全是一种通过消除危险的原因来确保安全的方法，通过改变机器设备，人为，环境等因素彻底消除诱因。而功能安全是通过一个有效的改善方法，在功能上确保可容忍范围的安全，即将风险降低到可接受的水平来确保安全。 ISO26262功能安全定义 Absence of unreasonable risk due to hazards caused by malfunctioning behavior of E/E systems. 没有由电子，电气系统故障行为导致的危险所引起的不合理的风险。 这段话的理解是不存在由电子电气系统的功能异常表现引起的危害而导致不合理的风险。比如，汽车正常行驶情况下安全气囊打开，这种功能异常是不合理的，也会带来安全方面的风险。这就是功能安全所需要避免的问题。总体来说，功能安全是指避免由系统功能性故障导致的不可接受的风险，它关注的是系统发生故障之后的行为，而不是系统的原有功能和性能。因此功能安全的目的就是当系统发生故障后，使系统进入安全的可控模式，避免对人身，财产造成伤害。 ISO26262适用范围 This document is intended to be applied to safety-related systems that include one or more electrical and/or eletronic (E/E) systems and that are installed in series production road vehicles, excluding mopeds. This docement does not address unique E/E systems in special vehicles such as E/E systems designed for driver with disabilities.(ISO26262-2018) 即该标准适用于所有的汽车、电动车。但是不包括轻便摩托车和特种车。 ISO26262的内容该功能安全标准主要包含了： 指导我们如何量化产品的安全等级； 知道我们如何根据不同的安全等级设计相应的安全措施 指导我们如何规避/控制系统性的故障和随机故障 知道我们如果管理功能安全(包括流程，技术分析方法等) 自适应巡航控制(ACC)功能安全","link":"/2019/05/05/work/002.ISO26262/"},{"title":"Autosar学习","text":"应用软件层AppL应用软件层最重要的就是SWC, 而SWC之间的通信需要接口，每个SWC由runnable组成，所以应用软件层的组成主要分为三个部分： 应用软件组件(SWC) AutoSAR的接口(Ports)和连接器(Connector) 可运行实体(Runnable) 例子：汽车顶灯控制汽车的顶灯一般有三种模式：常闭，常开，随着车的开关而开关的模式。实现汽车顶灯的控制需要传感器，处理单元和执行器。假设左右两个车门，左右两个车灯，一个开关传感器。该车顶的的控制需要7个SWC实现。但是这些SWC并非由一个ECU完成。 SWC之间的通信是通过虚拟功能总线(VFB)实现，该总线是片内外通信的结合体： 在片内通过RTE通信。每个SWC可以理解为一个.c文件，C文件之间的通信通过全局变量进行。 在片外通过片外的总线进行通信。常用的就是CAN总线。 在实际的汽车中，上述的7个SWC将被分配到两个ECU中。车灯开关，调光控制器和左右顶灯由车身顶部的ECU控制；左右车门和车门开关逻辑单元由专用的车门ECU芯片控制。两个ECU即连个控制器，分别位于车身前部的车门控制器和车身顶部的顶灯控制器。ECU内部通信通过RTE进行管理，跨ECU通信通过外部CAN总线进行。 SWC的类型SWC的类型总共有三种：原子级SWC(Atomic SWC)，集合级SWC(Composition SWC)，特殊的SWC。原子级SWC(Atomic SWC): 最小单元，不可再拆分，每个原子级SWC对应一个.c文件。比其更小的单元是runnable，即.c文件中的函数。每个SWC的功能基本上都是用来实现特定的算法。 集合级SWC(Composition SWC)：该级别的SWC将很多功能相近或者需要整合到一处的Atomic SWC整合起来，方便SWC归类。 集合级SWC类似于一个文件夹，用于存放相近功能的Atomic SWC. 特殊SWC：在实际的工程中，不止应用层需要设计SWC, 在基础软件层中，IO硬件抽象成层和复杂驱动(CDD)都需要手动添加代码。他们被看做一种特殊的SWC进行操作。 接口(Ports)的类型Ports存在于SWC之间作为通信的通道。或者SWC通过RTE和BSW做接口通信使用。Ports共有五种类型，如下图所示： S/R接口：用于传输数据。该数据传输过程通过RTE进行管理，避免数据出错。如同时调用同一数据可能出错。在数据传输时，一个接口可以包含多个数据，类似于通过结构体的传输。可以传输的数据类型包括基础的如int, float等，以及复杂数据类型如record, array等。 C/S接口：该接口的作用是提供操作，即Server提供函数供Client调用。调用的过程分为同步，异步两种。同步代表直接调用，相当于函数直接插入上下文运行；异步需要灯带，相当于函数在另一个线程中运行，不影响原线程运行。C/S接口的可以提供多个操作(函数)，可在ECU内部或者跨ECU调用。 可运行实体(Runnable)Runnable即SWC中的函数，在AutoSAR架构被DaVinci软件生成时，Runnable是空函数，需要手动添加代码实现相应功能。Runnable可以被触发，例如定时器触发，操作调用触发，以及接受数据触发等。 实时运行环境(RTE)RTE是AutoSAR架构中介于应用层和基础软件层之间，是AutoSAR虚拟功能总线VFB的接口的实现。其目的是为应用软件的SWC之间的通信提供基础设施服务，并促进包括OS在内的基础软件组建的访问。 RTE在Vector的工具链中是自动生成的，它的作用包括： 提供ECU内部或者跨ECU的通信管理，通过VFB, RTE就是VFB的具体实现。 提供对Runnable的管理功能，包括触发，唤醒等。即RTE可以把Runnable配置到OS对应的Task中去，生成的Task代码通过RTE的时间触发runnables的运行。注意这里RTE抽象了OS，防止SWC直接访问OS和BSW。 下图是车顶的控制系统中SWC与RTE以及BSW的组件之间的关系。 RTE对Runnables的运行支撑RTE作为运行环境的主要功能有： 通过RTE给runnables提供触发时间 通过RTE给runnables提供所需的资源 将BSW和SWC做隔绝：即runnables的运行条件由RTE提供，不能由OS直接提供。 Runnables的触发条件Runnables在设计时，需要考虑触发条件，负责无法运行。触发条件即一些特定的事件。AutoSAR中主要规定了以下触发事件： 初始化事件：初始化自动触发 定时器事件：给定一个周期性定时器，计时完成自动触发 接受数据事件(S/R): Receiver Ports接受数据即可触发 接受数据错误事件 数据发送完成事件：Send Ports发送完成即可触发 操作调用事件(C/S)： 模式切换事件 模式切换应答事件 异步服务返回事件：C/S可在异步下运行，即在异步调用Server函数时，被调用函数作为一个线程与当前程序并行运行，运行结束后返回时，将会触发异步服务返回事件。 RTE对Ports的支持RTE可以作为SWCs和BSW之间的交流途径： 作为VFB的具体实现 作为S/R接口的通信实现 作为C/S接口的通信实现 ECU内部通信/跨ECU通过COM口通信 实现AR-COM的回调功能，具体实现是在SWC中完成的，RTE负责完成这个回调机制其他特征： RTE提供了一种实现数据一致性的机制，即避免多个SWC同时操作一个数据出现问题。 RTE支持简单和复杂的数据类型 对SWC的类型进行实例化 R/S接口的实现在配置好DaVinci后，RTE会自动生成一些调用，在runnable上方，可以直接复制。下面是一个例子： /********************************************************************************************************************** * * Runnable Entity Name: RAB_Core0_100us * *--------------------------------------------------------------------------------------------------------------------- * * Executed if at least one of the following trigger conditions occurred: * - triggered on TimingEvent every 100us * ********************************************************************************************************************** * * Input Interfaces: * ================= * Explicit S/R API: * ----------------- * Std_ReturnType Rte_Read_AppPI_Can_ReceiverCore0_DEP_Can_Receiver(Idt_Can_Receiver *data) * * Output Interfaces: * ================== * Explicit S/R API: * ----------------- * Std_ReturnType Rte_Write_AppPI_Can_SenderCore0_DEP_Can_Sender(Idt_Can_Sender data, Rte_TransformerError *transformerError) * * Service Calls: * ============== * Service Invocation: * ------------------- * Std_ReturnType Rte_Call_ComM_UserRequest_GetCurrentComMode(ComM_ModeType *ComMode) * Synchronous Service Invocation. Timeout: None * Returned Application Errors: RTE_E_ComM_UserRequest_E_NOT_OK * Std_ReturnType Rte_Call_ComM_UserRequest_GetMaxComMode(ComM_ModeType *ComMode) * Synchronous Service Invocation. Timeout: None * Returned Application Errors: RTE_E_ComM_UserRequest_E_NOT_OK * Std_ReturnType Rte_Call_ComM_UserRequest_GetRequestedComMode(ComM_ModeType *ComMode) * Synchronous Service Invocation. Timeout: None * Returned Application Errors: RTE_E_ComM_UserRequest_E_NOT_OK * Std_ReturnType Rte_Call_ComM_UserRequest_RequestComMode(ComM_ModeType ComMode) * Synchronous Service Invocation. Timeout: None * Returned Application Errors: RTE_E_ComM_UserRequest_E_MODE_LIMITATION, RTE_E_ComM_UserRequest_E_NOT_OK * *********************************************************************************************************************/ /********************************************************************************************************************** * DO NOT CHANGE THIS COMMENT! &lt;&lt; Start of documentation area &gt;&gt; DO NOT CHANGE THIS COMMENT! * Symbol: RAB_Core0_100us_doc *********************************************************************************************************************/ ​​ /**********************************************************************************************************************​ * DO NOT CHANGE THIS COMMENT! &lt;&lt; End of documentation area &gt;&gt; DO NOT CHANGE THIS COMMENT!​ /​ FUNC(void, SWCCore0Basic_Type_CODE) RAB_Core0_100us(void) /* PRQA S 0850 / / MD_MSR_19.8 */ { /* * DO NOT CHANGE THIS COMMENT! &lt;&lt; Start of runnable implementation &gt;&gt; DO NOT CHANGE THIS COMMENT! * Symbol: RAB_Core0_100us *********************************************************************************************************************/ ​​ /**********************************************************************************************************************​ * DO NOT CHANGE THIS COMMENT! &lt;&lt; End of runnable implementation &gt;&gt; DO NOT CHANGE THIS COMMENT!​ *********************************************************************************************************************/​ } 直接调用： 相当于有一个全局变量，runnable可以直接读写这个变量。其写法采用一下语法：(指的是全局变量的名字，data指的是局部变量。这些函数都是在runnable中使用的) Std_ReturnType Rte_Read_&lt;port&gt;_&lt;data&gt; (&lt;DataType&gt; *data) Std_ReturnType Rte_Write_&lt;port&gt;_&lt;data&gt; (&lt;DataType&gt; data) 缓存调用： 该调用方式相当于先将全局变量复制到一个runnable的局部变量中，然后对局部变量进行操作，最后把这个局部变量赋值到全局变量中。 使用方法： &lt;DataType&gt; Rte_IRead_&lt;r&gt;_&lt;port&gt;_&lt;data&gt; (void) void Rte_IWrite_&lt;r&gt;_&lt;port&gt;_&lt;data&gt; (&lt;DataType&gt; data) 队列调用： RTE数据一致性的实现RTE对Interface的支持基础软件层(BSW)","link":"/2021/05/01/work/003.Autosar/"},{"title":"FreeRTOS学习笔记01","text":"基本概念 操作系统：操作系统是一个用以提供基础计算机功能的计算机程序，它可以向其他程序提供服务，应用来实现用户想要实现的功能。操作系统对应用程序的支持使得开发者在在开发应用程序是更加快捷，简单，易维护。 RTOS：大部分操作系统允许多个应用程序同时执行，这种成为多任务。但实际上，在任何一个时间点上只有一个进程在独立执行。由于应用程序切换足够快，好像所有的程序同时执行。操作系统中有一个调度器(Scheduler)的部分负责调度应用程序，决定什么时候执行哪个应用程序，调度器在每个程序之间的切换需要足够快速。实时操作系统费的调度器设计成可以提供确定的执行模式。实时性意味着嵌入式系统对某个具体事件的响应必须严格控制在一个预定的deadline内。实时操作系统会按照排序运行、管理系统资源，并为开发应用程序提供一致的基础。实时操作系统与一般的操作系统相比，最大的特色就是“实时性”，如果有一个任务需要执行，实时操作系统会马上（在较短时间内）执行该任务，不会有较长的延时。这种特性保证了各个任务的及时执行。 线程：线程是操作系统能够进行运算调度的最小单位，包含在进程中，是进程的实际运作单位。一条线程是进程中的一个单一控制流。线程有四枣红基本状态：产生，阻塞，非阻塞，结束。 进程：指计算机已运行的程序，是分时系统的基本运作单位。进程是程序的真正运行实例。进程有五种状态：新生，运行，等待，就绪，结束。在单CPU系统中，任何时间可能有多个进程在等待，但必定仅有一个进程在运行。 线程和进程区别：进程是资源分配的最小单位，线程是CPU调度的最小单位。进程和线程都是一个时间段的描述，是CPU工作时间段的描述，是运行中程序指令的描述。 实时操作系统的设计原则： 实时的消息、事件处理机制：常规的操作系统，消息队列是按照FIFO的方式进行调度。实时操作系统会提供基于优先级的处理方式。 提供内核级的优先级翻转处理方式：实时操作系统调度器最精彩遇到的问题是优先级翻转，因此对于类似信号量一类的API，都能提供抑制优先级翻转的机制，防止操作系统死锁。 减少粗粒度的所和长期关中断的使用：这里的所主要是指自旋锁(Spinlock)一类会影响中断的锁，也包括任何关中断的操作，在Windows和Linux的驱动中，为了同步的需要，可能会长期关闭中断，这里的长期可能是毫秒到百微秒级。但实时操作系统通常不允许长期关中断。对于非实时操作系统来说，如果收到外部中断，系统在处理中断的整个过程中可能会一直关中断。但实时操作系统的通常做法是吧中断作为一个事件通告给另外一个任务，interrupt handler在处理完关键数据以后，立即打开中断，驱动的中断处理程序以一个高优先级任务的方式继续执行。 系统级的服务也要保证实时性：对于一些系统级的服务，如文件系统操作，非实时系统过会缓存用户请求，并不直接把数据写入设备，或者建立一系列线程池，分发文件系统的请求。但是实时系统允许高优先级的任务有限写入数据。这种设计会牺牲性能，但是会保证系统的实时性。 避免提供实时性不确定的API：多数实时操作系统都不支持虚拟内存(page file / swap area),主要原因是缺页中断(page fault)会导致任务调度的不确定性增加。多数实时操作系统过都支持分页，但很少会使用虚拟内存，因为一次缺页中断的开销十分巨大，通常都是毫秒级。会导致用户程序执行的不确定性增加。 提供针对实时系统调度的专用API： 降低系统抖动：由于关中断的原因，通常情况下，操作系统的调度器不会太精确的产生周期性的调度。一个设计优秀的实时操作系统能把抖动降低到微妙甚至是百纳秒级别。 针对实时性设计的SMP和虚拟化技术： 实时性，硬实时，软实时实时性： 实时性也叫实时计算(real-time computing), 实时约束指的是从事件发生到系统回应之间的最长时间限制。实时程序必须保证在严格时间限制内响应。 换句话说就是，任务(Task)必须在给定的时间(Deadline)内完成。比如汽车安全气囊响应，在汽车检测到撞击后，汽车ECU以及执行器需要在40ms内完全打开气囊，否则就会对乘客安全造成威胁。这个时候就要求汽车ECU的程序运行满足实时性标准。 硬实时： The firm real-time definition allows for infrequently missed deadlines. In these applications the system can survive task failures so long as they are adequately spaced, however the value of the task’s completion drops to zero or becomes impossible. 软实时： The soft real-time definition allows for frequently missed deadlines, and as long as tasks are timely executed their results continue to have value. Completed tasks may have increasing value up to the deadline and decreasing value past it. 区别： 硬实时操作系统必须使任务在确定的时间内完成；软实时操作系统能使绝大多数的任务在确定时间内完成。因此，硬实时和软实时的差别是，软实时只能提供统计意义上的实时。只要任务及时执行就会具有价值，如果任务超出Deadline，只会导致价值的稍微降低。如计算机的声音系统就是软实时的任务。 而硬实时任务只要超时，任务的价值就会降低到零。 任务调度调度同来确定多任务环境下任务执行的顺序和获得CPU资源后能执行的时间长度。操作系统通过一个调度程序来实现调度功能。调度程序以函数的形式存在，用来实现操作系统的调度算法。调度程序本身并不是一个任务，是一个函数调用，可在内核的各个部分进行调用。调用调度程序的具体位置成为一个调度点(Scheduling point), 调度点通常处于一下位置：**(i)** 中断服务程序的结束位置；**(ii)** 任务因等待资源而处于等待状态；**(iii)** 任务处于就绪状态时。 在操作系统中，一个任务有三种典型状态： 正在运行(Running)：正在CPU中执行 待命(Ready)：等待执行 阻塞(Blocked)：任务暂停，等待一个事件的发生，例如接受一组数据 由于CPU在某个事件只能执行一个任务，因此大部分任务在多数事件处于阻塞或待命状态。可能大量的项目在待命列表里等待执行。这取决于系统所需的任务数量和调度器类型。通常情况下，简单的时间触发式调度器，待命任务列表的数据结构要尽可能缩短最坏情况下，程序在调度器关键部分的执行时间，防止其他任务一直在待命列表中无法及时执行。在这种调度器中，应该尽量避免抢占式任务，甚至应该关闭调度器之外的所有中断。并且待命列表的数据结构应该根据系统所需要最大任务数量进行优化。如果列表任务较多，双向链表是一个合适的结构。在任务列表的排序上，应该按照优先级对任务进行排序。这样可以保证高优先级任务的及时执行。 调度算法：实时操作系统需要采用各种算法和策略保证系统行为的可预测性，并且调用一切可利用的资源完成实时控制任务。 其实时调度算法分为三种类别：基于优先级的调度算法(Priority-driven scheduling-PD)，基于CPU使用比例的共享式调度算法(Share-drivescheduling-SD)，基于时间进程的调度算法(Time—driven schedulinq-TD)。 基于优先级的调度算法给每个进程分配一个优先级，在每次进程调度的时候，最高优先级任务首先被执行。算法的类型分为两种： 静态调度：静态调度在系统开始运行前进行调度，严格的静态调度在系统运行时无法对任务重新调度。静态调度的目标是把任务分配给各个处理机，并对每一处立即给出所要运行的静态运行顺序。静态调度算法实现简单 锁死锁： 死锁是指一组进程中的各个进程均占有不会释放的资源，但因互相申请被其他进程所占用的不会释放的资源而处于的一种永久等待的状态。 死锁的四个条件： 互斥条件(Mutual exclusion)：资源不能被共享，只能由一个进程使用 请求与保持条件(Hold and wait)：已经得到资源的进程可以再次申请新的资源 非剥夺条件(No pre-emption)：已经分配的资源不能从相应的进程中被强制的剥夺 循环等待条件(Circular wait)：系统中的若干进程组成的环路，该环路中每个进程都在灯带相邻进程正占用的资源 互斥锁： 互斥锁是一种独占锁，当线程A加锁成功后，此时的互斥锁已经被线程A独占了，只要A没有释放受众的锁，线程B加锁就会失败，于是就是会释放CPU让给其他线程，既然B释放了CPU，也就意味着线程B的加锁代码会被阻塞。对于互斥锁加锁失败而阻塞的现象，是由操作系统内核实现的。 自旋锁： 自旋锁是一种特殊的互斥锁，当资源被加锁后，其他线程想要再次加锁，此时该线程不会被阻塞睡眠而是陷入循环等待状态(CPU不能做其他事情)，循环检查资源持有者是否已经释放了资源，这样做的好处是减少了线程从睡眠到唤醒的资源消耗，但是会一直占用CPU资源。适用于资源的锁被持有时间段，而又不希望在线程的唤醒上花费太多资源的情况。 自旋锁为什么不能睡眠？ 因为需要循环检测lock变量。 内存管理 介绍一下FreeRTOS的内存管理？ heap_1：只申请不释放，适用于一旦创建好任务，信号量和队列就再也不会删除的应用。 heap_2：最佳匹配，即申请又释放，适用于可能会重复的删除的任务，队列，信号量等应用中，需要注意内存碎片的产生问题。 heap_3：简单封装malloc,free,对其进行线程保护。使用时需要编译器提供一个内存堆，编辑器库需要提供malloc()和free()函数。 heap_4：最佳匹配+合并相邻内存，具有不确定性，但不会产生严重的内存碎片 heap_5：最佳匹配+合并不连续的内存区。 简述RTOS中，栈空间的最大使用率和栈溢出的检测方法？ 方法一：在任务切换时检测任务指针是否越界，如果越界就会在任务切换时触发栈溢出的钩子函数 方法二：在任务创建的时候将任务战所有数据初始化为0Xa5，任务切换进行任务栈检测时检测末尾的16个字节是否都是0xa5，通过这种方式检测栈是否溢出。 参考文章[1] https://blog.csdn.net/u012993936/article/details/41145863[2] https://zhuanlan.zhihu.com/p/86861756","link":"/2021/05/07/work/004.RTOS/"},{"title":"FreeRTOS学习笔记02","text":"FreeRTOSFreeRTOS是一个迷你的实时操作系统内核。作为一个轻量级的操作系统，功能包括：任务管理、时间管理、信号量、消息队列、内存管理、记录功能、软件定时器、协程等，可基本满足较小系统的需要。 FreeRTOS是为小型嵌入式系统设计的可裁剪实时内核。其主要特点有： 调度器支持抢占式调度，协助式调度，或者两者混合。时间片可选 占用空间小，简单，易用 FreeRTOS的源码结构在FreeRTOS v9.0版本中，FreeRTOS的代码主要包含两个文件夹：FreeRTOS_CORE和FreeRTOS_PORTABLE。这两个文件夹下包含多个.C文件。 port.c: 针对不同硬件平台的接口，定义与硬件接口相关的代码 heap_4.c： 内存管理相关 croutine.c：协程相关 event_groups.c：事件标志组相关 list.c：管理系统实际会应用到list，是FreeRTOS的一种基础数据结构 tasks.c：任务创建、挂起、恢复、调度相关 timers.c：软件定时器相关 queue.c：管理tasks之间的通信(message queue的概念) FreeRTOSConfig.h：宏定义，配置RTOS所需要的资源 FreeRTOS的任务间通信机制裸机编程中，一个复杂的功能通常需要多个子函数来实现，不同的子函数之间的通常采用一些全局变量来实现联系。在RTOS中，我们不仅可以使用全局变量，还可以采用系统自带的任务间通信机制。这种机制更加受推荐。其原因是： 阻塞等待机制比轮询等待更加高效：全局变量当用作某种事件的标志是，获取该标志的任务需要轮询检测标志位的状态是否变化。这样会产生大量的无效判断。如果使用任务间通信阻塞等待的机制，CPU可以转而处理其他事情，当标志变化时解除阻塞。又可以及时执行后续的处理。 全局变量会产生不可重入函数导致逻辑混乱：RTOS运行时，CPU需要调用不同的函数，如果全局变量使用不恰当，会导致原本设计的逻辑产生混乱。比如某个低优先级任务正在访问某个公共函数，并对函数中的全局变量进行了修改。还未退出函数时，更高优先级的任务抢占了CPU的使用权，并对该函数的全局变量进行了修改。此时低优先级任务若认为自己修改变量成功，执行后续逻辑时，就会发生错误。 FreeRTOS任务间的通信方式： 信号量(Semaphore): 用于任务间的同步，一个任务以阻塞方式灯带另一个任务释放信号量。 互斥量(Mutex)：用于任务间共享资源的互斥访问，使用前获取锁，使用后释放锁。 事件标志组(EventGroup): 用于任务间的同步，相比信号量，事件标志组可以等待多个事件的发生。 消息队列(Queue): 类比全局数据，它可以一次发送多个数据(一般将数据定义成结构体发送)，每次数据的大小固定不变。 流缓冲区(SteamBuffer)：在队列的基础上，优化的一种更加适合的数据结构，可以一次写入任意数量的字节，并且可以一次读取任意数量的字节。 消息缓冲区(MessageBuffer)：在流式缓冲区的基础上实现的，可以对消息进行设计改进。每一条消息的写入增加了一个字节用来表示该消息的长度，读取时需要至少一次性读出一条消息，否则会返回0. 任务通知(Notify): 不同于上面的任务通信方式(使用某种通信对象，通信对象是独立于任务的实体，有单独的存储空间，可以实现数据的传递和较复杂的同步，互斥功能)， 通知是发向一个指定的任务的，直接改变该任务 TCB的某些变量。 FreeRTOS队列在实际应用中，一个任务或中断服务函数经常需要和另一个任务进行消息传递。裸机情况下通常通过全局变量实现。但是操作系统使用全局变量的方式会涉及“资源管理”问题。FreeRTOS中采用队列机制完成任务与任务，和任务与中断之间的消息传递。 队列可以存储有限的，大小固定的数据项目。 内存管理FreeRTOS创建任务、队列、信号量有两种方法： 第一种是由用户自行定义所需的RAM，这种方法也叫静态的方法。静态方法的函数一般由Static结尾，比如任务创建 xTaskCreateStatic()。 使用此函数创建任务的时候需要用户定义任务堆栈。 另一种是动态的申请所需的RAM，使用动态内存管理时，FreeRTOS内核在创建任务、队列、信号量的时候会动态的申请RAM。C语言标准库的malloc()和free()也可以实现动态内存管理，但这种方法在小型嵌入式系统中效率不高，会占用很多代码空间，并且他们的线程不是安全的，程序执行的时间也是不确定的，此外还会导致内存碎片。因此在FreeRTOS中，内核采用 pvPortMalloc()代替 malloc() 申请内存，采用 vPortFree()函数释放内存。关于内存分配，FreeRTOS提供了5这种内存分配的方法： 也就是在5个.c文件，heap_1.c, heap_2.c, heap_3.c, heap_4.c, heap_5.c。 内存碎片：内存分配与管理的方法中需要解决的问题之一就是内存碎片，其产生过程如下图所示，一个新的内存堆被系统按照应用需求分成多个大小不同的内存块。应用在使用完内存后就会进行释放，同时新的应用产生也需要分配新的可用该内存。经过多次申请和释放后，内存块被不断地分割，导致内存中存在大量的很小的内存块。这些内存块太小导致大多数应用无法使用，因此就形成了内存碎片。这些内存碎片的不断增加会导致实际可用内存越来越少。最终应用程序因为分配不到合适的内存而崩溃。而FreeRTOS的heap_4.c就提供了一个解决内存碎片的方法，即将内存碎片进行合并组成一个新的可用的大内存块。 heap_1.c简介动态内存分配需要一个内存堆，在FreeRTOS中的内存堆为ucHeap[],大小为configTOTAL_HEAP_SIZE. heap_1特性如下： 使用一旦创建好任务，信号量和队列就再也不会删除的应用，实际上大多数的FreeRTOS的应用都是这样的。 具有可确定性(执行所花费的时间大多数都是一样的)，而且不会导致内存碎片。 代码实现和内存分配的过程都非常简单，内存是从一个静态的数组中分配的，也就是适合与那些不需要动态分配内存的应用。 heap_2.c简介 heap_3.c简介 heap_4.c简介heap_4提供了一个最优的内存分配方法，不像heap_2, heap_4会将内存中的碎片合并成一个大的可用内存块，他提供了内存合并算法。内存堆为ucHeap[], 大小同样为configTOTAL_HEAP_SIZE。可以通过函数xPortGetFreeHeapSize()获取剩余内存大小。 heap_4特性如下： 可以用在那些需要重复创建和删除任务、队列、信号量和互斥信号量等应用中。 不会像heap_2那样产生严重的内存分配碎片，即使分配的内存大小是随机的。 具有不确定性，但是远比C标准库的malloc()和free()效率高。 heap_5简介heap_5使用了heap_4相同的合并算法，内存管理实现基本相同，但是heap_5允许内存堆跨越多个不连续的内存段。如果使用heap_5需要调用函数xPortDefineHeapRegions()来对内存堆做初始化处理，该函数执行完之前禁止调用任何会调用pvPortMalloc()的函数。 参考资料：[1] FreeRTOS源码探析之——任务调度相关","link":"/2021/05/09/work/005.FreeRTOS/"},{"title":"嵌入式面试常见问题整理","text":"基本概念单工，半双工，全双工 单工：简单的说就是一方只能发信息，另一方则只能收信息，通信是单向的。 半双工：比单工先进一点，就是双方都能发信息，但同一时间则只能一方发信息。 -全双工：比半双工再先进一点，就是双方不仅都能发信息，而且能够同时发送。 FLASH 和 EEPROM区别基本概念： ROM： Read-Only Memory RAM： Random Access Memory FLASH: Flash 存储器（FLASH EEPROM）又称闪存，快闪。它是EEPROM的一种。它结合了ROM和RAM的长处。不仅具备电子可擦除可编辑（EEPROM）的性能，还不会断电丢失数据同时可以快速读取数据 EEPROM: Electrically-Erasable Programmable Read-Only Memory SRAM：静态RAM，读写速度非常快，比较昂贵。一般用于CPU的一级缓冲，二级缓冲。 DRAM：动态RAM，DRAM保留数据的时间很短，速度比SRAM慢，但是比任何ROM快。计算机的内存是DRAM。 FLASH和EEPROM的最大区别是FLASH按扇区操作，EEPROM则按字节操作，二者寻址方法不同，存储单元的结构也不同，FLASH的电路结构较简单，同样容量占芯片面积较小，成本自然比EEPROM低，因而适合用作程序存储器，EEPROM则更多的用作非易失的数据存储器。 目前的单片机，RAM主要是做运行时数据存储器,FLASH主要是程序存储器,EEPROM主要是用以在程序运行保存一些需要掉电不丢失的数据. Nano Flash和NOR Flash的区别：目前Flash主要有NANO和NOR两种 NOR Flash：该种Flash的读写和创建的SDRAM读写一样，用户可以直接运行装载在NOR Flash里面的代码，这样可以减少SRAM的容量从而节约成本。 NANO Flash：NAND Flash没有采取内存的随即读取技术，它的读取是一次读取一块的形式来进行的，通常是一次读取512个字节，采用这种技术的Flash比较廉价，用户无法直接运行上面的代码。 总线协议CAN总线协议(Controller Area Network)CAN总线协议是由博世开发的一种基于消息广播模式的串行通信总线，该协议非常适合于现场控制领域，主要用于实现汽车ECU之间的可靠通信。该通讯协议最高速率可达到1Mbps, 容错能力强。CAN控制器包含强大的检错和处理机制。另外CAN的节点之间不会传输大数据块，一帧CAN消息最多传输8字节用户数据。 总线特点 多主控制，总线空闲时所有单元都可以发送消息，最先访问总线的单元获得发送权，多个单元同时发送时，发送优先级高的可以发送。发送的消息保温不包含原地址和目标地址，只通过标识符表示消息的功能和优先级。 总线为事件触发型，只有消息要发送时，节点才向总线上广播消息; 同时每个节点也可以通过发送远程帧请求其他节点发送数据。 总线上可同时连接多个节点，可连接节点总数在理论上是没有限制的，实际可连接的节点数受总线上的时间延迟和电气负载限制。 符合OSI通信系统参考模型，属于物理层和数据链路层。两线式总线结构，电气信号为差分式，通信介质可以采用双绞线，同轴电缆和光导纤维，一般采用双绞线。 总线电平：显性(Dominant): 0, 隐性(Recessive): 1, CAN总线的信号电平具有线与特性，即显性电平0总是会掩盖隐性电平1，如果不同的节点同时发送显性和隐性电平，总线总是表现出显性电平。只有所有节点发送隐性电平是，总线才表现为隐性。线与特性是CAN总线仲裁机制的电路基础。 高速CAN：总线通信速度最高1Mbp(40m条件下)。高速CAN时，CANH与CANL电压相同时为逻辑“1” (CANH=CANL=2.5V)。CANH和CANL电压相差2V时为逻辑“0” (CANH=3.5V, CANL=1.5V)。高速CAN收发器在共模电压范围内(-12V~12V),将CANH和CANL电压差大于0.9V成为显性状态，将CANH和CANL电压差小于0.5定义为隐性状态。 低速CAN：定义CANH和CANL电压相差 5V （CANH = 0V, CANL = 5V）时为逻辑“1”，相差 2.2V （CANH = 3.6V, CANL = 1.4V）时为逻辑“0”。 CAN报文帧结构：在CAN总线上，报文以“帧”的形式发送，每个报文帧包含以下部分： 帧起始：总线空闲时为隐性状态，帧起始由单个显性位构成，标志报文开始，在总线上起同步作用。 仲裁段：仲裁段由报文的标识符完成，即ID，标准CAN的标识符为11位，扩展CAN中为29位。 控制段：主要定义了数据域的字节长度，通过数据长度码，接收节点可以判断报文数据是否完整。 数据域：主要包含0~8个字节数据。 CRC域：循环冗余码校验 帧结束：由一串七个隐性位组成，表示报文帧的结束。 CAN报文帧种类 （1）数据帧：由发送节点发出，包含0 - 8个数据字节。 （2）远程帧：发送远程帧向网络节点请求发送某一标识符的数据帧。 （3）错误帧：总线节点发现错误时，以错误帧的方式通知网络上的其他节点。 （4）过载帧：发送过载帧，表示当前节点不能处理后续的报文（如帧延迟等）。 SPI协议SPI(Serial Peripheral interface)串行外围设备接口，该接口主要用在EEPROM，Flash，实时时钟，AD转化器，数字信号处理器和数字信号解码器之间。 该协议是一种高速的，全双工同步串行通信总线。 没有速度限制，一般可达到10Mbps。 主要有四根线：MOSI， MISO，SCLK，CS(片选，选择从设备)。数据在上升下降沿改变。 优点：全双工通信，简单，传输速率快 缺点：没有指定的流控制，没有应答机制确认是否收到数据，相对IIC可靠性不高。 SPI的四种模式：SPI有四种工作模式，SPI为了和外设进行数据交换，根据外设工作要求，其输出串行同步时钟的极性(CPOL)和时钟相位(CPHA)可以进行配置。CPOL决定SPI空闲时，时钟信号的电平。CPHA决定SPI在SCLK的第几个边沿开始采样数据。 CPOL=0：串行同步时钟的空闲状态是低电平 CPOL=1：串行同步时钟的空闲状态是高电平 CPHA=0：SPI在串行同步时钟的第一个跳边沿开始采样 CPHA=1：SPI在串行同步时钟的第二个跳边沿开始采样 DMADMA(Direct Memory Access),即直接存储器访问，DMA的传输方式可以无需CPU直接进行控制传输，也没有中断处理方式那样的保护现场和恢复现场的过程。通过硬件为RAM与I/O设备开辟一条直接传输数据的通路，可以使CPU的效率大为提高。 作用： 用于内存和内存之间或内存和外设之间的高速数据传输。 DMA传输包括哪些操作？(STM32为例) 每一次DMA传输包括三个操作 通过DMA的寄存器寻址，从外设数据寄存器或存储器单元加载数据。 DMA计数器在数据存储结束后递减，该计算器中包含仍需执行的事务数目。 产生事件后，外设会向DMA控制器发送请求信号，DMA控制器根据通道优先级处理该请求，只要DMA控制器访问外设，DMA控制器就会向外设发送确认信号，外设获得确认信号后，便会立即释放请求。一旦外设使请求失效，DMA就会释放确认信号。如果有更多的请求，外设可以启动下一个事务。 C语言Static关键字作用Const关键字作用Voilatile关键字作用","link":"/2021/05/03/work/Emmbed_system_QA/"},{"title":"Dynamic Occupancy Grid Prediction for Urban Autonomous Driving","text":"Abstract长期状况预测对智能车辆起着至关重要的作用。仍然需要克服的主要挑战是如何预测具有多个道路用户（例如行人，自行车和机动车辆）相互交互的复杂市区场景。该贡献在于通过结合用于环境表示的贝叶斯过滤技术和作为长期预测器的机器学习来解决这一挑战。更具体地说，动态占用网格图被用作深度卷积神经网络的输入。这产生了使用单个时间步长的空间分布速度估计值进行预测而不是原始数据序列的优势，从而减轻了处理多个传感器的输入时间序列的常见问题。此外，卷积神经网络具有使用上下文信息的固有特性，从而可以对道路用户交互进行隐式建模。损失函数中采用了像素级平衡，以抵消静态和动态单元之间的极端不平衡。主要优点之一是由于全自动标签生成而导致的无监督学习特征。在多个小时记录的传感器数据上对提出的算法进行训练和评估，并将其与蒙特卡洛模拟进行比较。实验表明，可以对复杂的交互过程进行建模 Introduction过去几十年的研究在自动驾驶领域取得了巨大的成功。通过将自动驾驶汽车与人类驾驶员进行比较，人类可以通过估计未来场景演变的能力来补偿相对较长的反应时间。这还可以实现战略性和前瞻性的行为，难以用机器的快速反应和精确感知来弥补。因此，自动驾驶的长期状况预测仍然是要克服的主要挑战。我们应对汽车，卡车，自行车和行人共享道路的高度复杂的城市环境。道路使用者会各自做出反应，但具有特定于类型的运动约束。最重要的是，步行或驾车的人在这种情况下并不会独立行动，而是互动并考虑他人的可能行为。因此，个人的决定和道路可能会对某人或其他人的未来行为产生影响。因此，这种交通场景可能演变成许多可能的未来场景星座，从而激发了对预测结果进行概率表示的需求。简而言之，城市自动驾驶的长期状况预测应该能够纳入所有已知交通参与者的互动，并且由于问题的不确定性，可以应对可能结果的差异 交互和运动动力学模型是改善预测的常用工具。文献涵盖使用工程和学习模型进行的长期预测。手动设计道路用户预测中的依赖性（例如，使用数字地图或智能驾驶员模型[1]）通常是相当局限性的假设，例如，车道跟踪[2]或汽车跟踪[3]场景。另外，考虑到上下文和对象关系的手工模型往往是高维的[1]，[4]，这激发了机器学习的替代性。与机器学习在分类方面的巨大成功相一致，提出了一些方法来预测关于离散操纵类的未来操纵，例如，停止，直行或转弯[5]，[6]。然而，就时间序列而言预测轨迹与就泛化而言预测机动类别不同。为了在算法输出处获得时空分布，这是数据表示的问题。 Wiest [7]，例如，切比雪夫多项式的预测参数在高斯混合模型中被视为随机变量 与算法输出相反，考虑输入处原始传感器数据的时间序列，尽管有数据表示，但仍会出现一些技术问题。在2018年5月21日至25日于澳大利亚布里斯班举行的IEEE国际机器人与自动化大会（ICRA）上，采样频率的变化，异步传感器的缩放和转换，或时域输入不规则，都是机器学习面临的挑战[8 ]，但已由传感器融合社区进行了深入研究[9]，[10]。从机器学习的角度来看，不是从时间序列中学习时间特征并面对上述问题，而是通过表示短期动态特征的一阶微分方程来关联单个时间戳的状态变量。此外，我们假设空间上下文可以弥补长期输入序列的不足。这个假设是受股票市场预测研究的启发[11]，众所周知，使用过去的时间序列不足以预测未来的股票趋势[12]。而且，还不清楚它们是否有帮助[13]。然而，可以通过上下文信息（例如Twitter情绪[14]或在线聊天[15]）来提高预测性能[11]。如图1所示，可以在动态占用栅格图（DOGMa）中看到空间上下文。DOGMa使用贝叶斯滤波[16]融合各种传感器，并采用了鸟瞰图（静态和动态）。 每个多通道像素或单元包含概率占用率和速度估计。 此外，DOGMas的类似图像的数据结构自然建议使用卷积神经网络（CNN）来利用上下文信息以及不同对象与给定基础结构之间的依赖关系。 因此，在这项工作中，结合了基于工程和基于学习的方法的优势。 卷积神经网络（CNN）用于对长期运动进行建模，输入端使用当前动态环境的贝叶斯估计。 对于训练，无需执行手工标记，但是，使用未来和过去的估计方法应用了将稀有动态与静态网格单元分离的算法。 首先，这可以在训练过程中在静态区域和动态区域之间实现平衡，而且可以对当前环境进行学习，得出的结果优于工程方法。 论文的剩余部分的结构如下。 在第二部分中，我们概述了动态占用网格。 第三部分介绍了用于无监督学习的全自动标签生成。 IV简要介绍了所采用的CNN架构。 在第V节中，引入了像素平衡损失函数，以抵消动态单元的高代表性。 结果显示在第七节，随后是结论在第八节 Filtered Dynamic Input如图1所示，由多个传感器提供的动态占用栅格图（DOGMa）[16]可以提供鸟瞰图，例如360°的环境表示。DOGMa数据以R^|Ω|×W×H提供，空间宽度W和高度H分别指向东和北。 通道Ω={MO，MF，vE，vN，σ2vE，σ2vN，σ2vE，vN} 包含自由空间MF∈[0，1]和占用MO∈[0，1]的Dempster-Shafer质量，指向东vE和向北vN的速度以及速度方差和协方差。占用概率的计算公式为： 高PO表示图1中的暗像素。尽管图1仅包含3个RGB通道，但所有通道Ω和扩展都可用于馈送神经网络。 由于两个主要优点，有意避免将原始传感器数据输入到CNN中：1）DOGMa单元为每个单元提供带有协方差矩阵的速度估计，从而导致空间占用和速度分布。 为此，该算法使用了与时域中的等待时间和方差有关的高级传感器融合技术，这些技术很难通过基于学习的方法来补偿[8]。 2）DOGMa输出格式与传感器设置无关，例如将雷达和激光或仅具有不同范围的激光融合在一起，这在训练具有变化传感器的神经网络时可能是有利的。 通常，该算法使用工程模型来利用依赖传感器的优势。 这些模型可以，例如，考虑从激光测量获得的自由空间，或来自雷达的自我运动补偿的多普勒速度[16]。 如果传感器规格发生变化，则可以轻松调整参数 DOGMa基于顺序蒙特卡洛滤波。 网格单元具有固定的位置和宽度，并且地图边框会移动单元宽度，以使移动中的自我车辆保持在中心单元内。 过滤器算法在两个模块中运行：在第一个模块中，使用传感器特定的测量模型将传感器数据转换为经典的占用网格图[17]，[18]。 这些网格用作第二个模块的通用数据接口，一个粒子过滤器估计空间占用率和速度分布[16]。 每个网格单元均独立更新，并且不对单元之间的交互进行建模。 尽管提出了从网格单元中提取建模对象的手工方法[19]，但在这项工作中，不需要在CNN输入或标记时生成对象。 由于在Dempster-Shafer域[20]中的实现，DOGMa提供了有关占用率，自由空间和不可观察区域的概率信息。 Automatic Output Label Generation标注通常是一个广泛的过程，也是监督学习中的主要缺点之一。幸运的是，根据场景预测的性质，可以在以后的时间观察到所需的算法输出。一旦可以应用自动标签提取，生成培训数据就相对容易了。但是，大约99.75％的环境数据是静态的，这可能会使学习算法偏向于预测未来等于当前输入样本的琐碎结果。因此，需要对代表性不足的动态环境进行细分以应用平衡方法。文献[16]提出了一种在感知时在线对动态细胞进行分类的方法。但是，当静态物体进入视场或在嘈杂区域（例如，静态物体的边界）时，使用当前的像元速度估计会导致分类错误。由于标签提取可以离线进行，因此可以使用将来和过去的使用过程来实现更好的分类，从而例如区分正在生长的静态部分和实际运动的对象. 如图2所示，对于每个单元，提取准时间连续PO（t）。该图说明了在恒定空间坐标（E，N）下针对网格单元的PO（t）的提取，而自我车辆是 自身在动态环境中移动。 期望的预测结果是一个序列： 其中时间步长序列k =（1、2，…）可以在CNN的相应输出通道中表示。 另外，需要分割成静态和动态部分。 因此，一个可以写做： 在静态环境中具有恒定的占用概率PO，s和描述占用概率的序列（PO，d（k））完全源自动态元素。可以通过在静态和动态时间ts和td中按单元对数据进行划分来在时域中自动进行分段：当对象遍历某个单元时，DOGMa中的贝叶斯滤波器会平滑收敛到最大PO，而当目标遍历单元时，它会回到静态水平。物体离开细胞（见图2）。 PO（t）的上升接着信号的下降被用来检测动态对象的存在，因此之间的时间定义了间隔td。该计算基于二阶导数，然后进行非最大抑制。在离线提取序列中，通过将td内的时间步长（PO（k））设置为max（PO（td））来校正DOGMa滤波器的收敛延迟。曲线PO（t）可能非常嘈杂，尤其是在未知区域（PO = 0.5）或静态，自由和未知之间的空间过渡时。因此，使用时域中的高斯滤波器对Ω中的数据进行平滑处理。相应地平滑了空间域中的噪声，例如单个动态单元。 最后，（3）中的恒定静态PO，s由ts∈（t0，t0 + T）\\ td的PO，s（ts）的中位数计算，其中t0表示DOGMa输入时间，T表示预测范围。 R | T |×W×H的网络输出提供了通道T = {PO，s，PO，d（1），PO，d（2），…，PO，d（| T | − 10) CNN Architecture深度神经网络架构可以利用DOGMa输入中的遥远关系。 但是，输出结构也应提供空间分布。 [21]（DeconvNet）和[22]（Fully Convolutional Networks，FCN）的网络体系结构在按比例缩减级联之后提供按比例缩放层。 这些方法旨在从单个输入图像进行像素精确的图像分割。 Shelhamer和Long [22] [23]周围的小组使用Zeiler和Fergus [24]提出的去卷积运算来缩小采样的特征图的大小，以实现可视化目的。 上采样是在单层中执行的，而较早的层结果则具有较高的分辨率，用于获得精细的输出图。 与可学习的内核相反，[21]和[25]的作者使用[26]的解池方法。[22]使用单个上采样步骤，[21]分阶段执行下规模镜像下采样阶段的升级，并重用最大池下规模的索引以通过下池进行上规模。 通过在每个解池层中进行后续卷积，可以使所得的稀疏特征图变得密集。 在我们的方法中，我们遵循由[21]提出的，由按比例缩小的级联和按比例放大的阶段进行镜像处理的单个输入DOGMa的策略。 但是，我们选择了可学习的反卷积内核而不是解池，并结合了按比例缩小阶段的绕过结果。 除了像素分类，我们的目标是在未来的时间步长预测占用的单元格。 此外，网络将环境的静态和动态部分分段，并在一个通道中传递静态网格单元的占用率，而在其余通道中传递动态单元的占用率。","link":"/2020/02/09/Major/Self_driving/Paper_self_driving/"},{"title":"Linux Bash总结","text":"快捷键移动光标ctrl+b: 前移一个字符(backward)ctrl+f: 后移一个字符(forward)alt+b: 前移一个单词alt+f: 后移一个单词ctrl+a: 移到行首（a是首字母）ctrl+e: 移到行尾（end）ctrl+xx: 行首到当前光标替换编辑命令alt+.: 粘帖最后一次命令最后的参数（通常用于mkdir long-long-dir后, cd配合着alt+.）alt+d: 删除当前光标到临近右边单词开始(delete)ctrl+w: 删除当前光标到临近左边单词结束(word)ctrl+h: 删除光标前一个字符（相当于backspace）ctrl+d: 删除光标后一个字符（相当于delete）ctrl+u: 删除光标左边所有ctrl+k: 删除光标右边所有ctrl+l: 清屏ctrl+shift+c: 复制（相当于鼠标左键拖拽）ctrl+shift+v: 粘贴（相当于鼠标中键）其它ctrl+n: 下一条命令ctrl+p: 上一条命令alt+n: 下一条命令（例如输入ls, 然后按’alt+n’, 就会找到历史记录下的ls命令）alt+p: 上一条命令（跟alt+n相似）shift+PageUp: 向上翻页shift+PageDown: 向下翻页 ctrl+r: 进入历史查找命令记录， 输入关键字。 多次按返回下一个匹配项 参考资料 https://blog.51cto.com/u_15311900/3182821","link":"/2022/03/04/Notebook/Linux/Linux_Bash/"}],"tags":[{"name":"德国驾照","slug":"德国驾照","link":"/tags/%E5%BE%B7%E5%9B%BD%E9%A9%BE%E7%85%A7/"},{"name":"Blogs","slug":"Blogs","link":"/tags/Blogs/"},{"name":"CV","slug":"CV","link":"/tags/CV/"},{"name":"object detection","slug":"object-detection","link":"/tags/object-detection/"},{"name":"C++","slug":"C","link":"/tags/C/"},{"name":"建模","slug":"建模","link":"/tags/%E5%BB%BA%E6%A8%A1/"},{"name":"photo","slug":"photo","link":"/tags/photo/"},{"name":"航拍","slug":"航拍","link":"/tags/%E8%88%AA%E6%8B%8D/"},{"name":"Tensorflow","slug":"Tensorflow","link":"/tags/Tensorflow/"},{"name":"Apollo","slug":"Apollo","link":"/tags/Apollo/"},{"name":"nvidia","slug":"nvidia","link":"/tags/nvidia/"},{"name":"point cloud","slug":"point-cloud","link":"/tags/point-cloud/"},{"name":"pytorch","slug":"pytorch","link":"/tags/pytorch/"},{"name":"嵌入式","slug":"嵌入式","link":"/tags/%E5%B5%8C%E5%85%A5%E5%BC%8F/"},{"name":"Self-driving","slug":"Self-driving","link":"/tags/Self-driving/"}],"categories":[{"name":"术业","slug":"术业","link":"/categories/%E6%9C%AF%E4%B8%9A/"},{"name":"慎思","slug":"慎思","link":"/categories/%E6%85%8E%E6%80%9D/"},{"name":"玩物","slug":"玩物","link":"/categories/%E7%8E%A9%E7%89%A9/"}]}